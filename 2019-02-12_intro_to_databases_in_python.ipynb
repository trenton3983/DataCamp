{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Notebook Author: [Trenton McKinney](https://trenton3983.github.io/)\n",
    "- Course: **[DataCamp: Introduction to Databases in Python](https://learn.datacamp.com/courses/introduction-to-relational-databases-in-python)**\n",
    "- This [notebook](https://github.com/trenton3983/DataCamp/blob/master/2019-07-19_fraud_detection_python.ipynb) was created as a reproducible reference.\n",
    "- Most of the material is from the course, however, code updates have been introduced for compatibility with `sqlalchemy v2.0.29`.\n",
    "- I completed the exercises\n",
    "- If you find the content beneficial, consider a [DataCamp Subscription](https://www.datacamp.com/pricing?period=yearly).\n",
    "- Test in:\n",
    "  - pandas version: 2.2.1\n",
    "  - matplotlib version: 3.8.4\n",
    "  - SQLAlchemy version: 2.0.29\n",
    "  - PyMySQL version: 1.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine, Table, MetaData, select, and_, desc, func, case, cast, Float\n",
    "from sqlalchemy import Column, String, Integer, Boolean, insert, update, delete, inspect, text\n",
    "from sqlalchemy.orm import Session\n",
    "import pymysql\n",
    "from pprint import pprint as pp\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 300)\n",
    "pd.set_option('display.expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Files Location\n",
    "\n",
    "* Most data files for the exercises can be found on the [course site](https://www.datacamp.com/courses/introduction-to-relational-databases-in-python)\n",
    "    * [Census (CSV)](https://assets.datacamp.com/production/repositories/274/datasets/7a5a4567430ee737c70994d1c4747f252e0fd527/census.csv)\n",
    "    * [Census (SQLite)](https://assets.datacamp.com/production/repositories/274/datasets/f6eda83e7fb90ac06a22af4132a355933763785c/census.sqlite)\n",
    "    * [Employees (SQLite)](https://assets.datacamp.com/production/repositories/274/datasets/af705f788c225cad7e6ef405ed5490db36ed03bf/employees.sqlite)    \n",
    "* Other data files may be found in my [DataCamp repository](https://github.com/trenton3983/DataCamp/tree/master/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data File Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_csv_data = 'data/intro_to_databases_in_python/census.csv'\n",
    "census_sql_data = 'sqlite:///data/intro_to_databases_in_python/census.sqlite'\n",
    "employees_sql_data = 'sqlite:///data/intro_to_databases_in_python/employees.sqlite'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Introduction to Databases in Python\n",
    "\n",
    "***Course Description***\n",
    "\n",
    "In this Python SQL course, you'll learn the basics of using Structured Query Language (SQL) with Python. This will be useful since whether you like it or not, databases are ubiquitous and, as a data scientist, you'll need to interact with them constantly. The Python SQL toolkit SQLAlchemy provides an accessible and intuitive way to query, build & write to SQLite, MySQL and Postgresql databases (among many others), all of which you will encounter in the daily life of a data scientist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Basics of Relational Databases\n",
    "\n",
    "In this chapter, you will become acquainted with the fundamentals of Relational Databases and the Relational Model. You will learn how to connect to a database and then interact with it by writing basic SQL queries, both in raw SQL as well as with SQLAlchemy, which provides a Pythonic way of interacting with databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### 1.a: Introduction to Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A database consists of tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/trenton3983/DataCamp/blob/master/Images/intro_to_databases_in_python/tables.JPG?raw=true \"Tables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table consists of columns and rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/trenton3983/DataCamp/blob/master/Images/intro_to_databases_in_python/columns_rows.JPG?raw=true \"Columns and Rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tables can be related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/trenton3983/DataCamp/blob/master/Images/intro_to_databases_in_python/related.JPG?raw=true \"Related\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relational Model\n",
    "\n",
    "Which of the following is not part of the relational model?\n",
    "\n",
    "Answer the question\n",
    "\n",
    "1. Tables\n",
    "2. Columns\n",
    "3. Rows\n",
    "4. __Dimensions__\n",
    "5. Relationships\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to a Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meet SQLAlchemy\n",
    "\n",
    "* Two Main Pieces\n",
    "    * Core (Relational Model focused)\n",
    "    * ORM (User Data Model focused)\n",
    "        * Object Relational Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are many types of databases\n",
    "\n",
    "* SQLite\n",
    "* PostgreSQL\n",
    "* MySQL\n",
    "* MS SQL\n",
    "* Oracle\n",
    "* Many more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connecting to a database\n",
    "\n",
    "```python\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///census_nyc.sqlite')\n",
    "connection = engine.connect()\n",
    "```\n",
    "\n",
    "* Engine: common interface to the database from SQLAlchemy\n",
    "* Connection string: All the details required to find the database (and login, if necessary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A word on connection strings\n",
    "* 'sqlite:///census_nyc.sqlite'\n",
    "* Driver+Dialect Filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What’s in your database?\n",
    "\n",
    "* Before querying your database, you’ll want to know what is in it: what the tables are, for example:\n",
    "\n",
    "```python\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///census_nyc.sqlite')\n",
    "print(engine.table_names())\n",
    "Out: ['census', 'state_fact']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection\n",
    "\n",
    "* Reflection reads database and builds SQLAlchemy Table objects\n",
    "\n",
    "```python\n",
    "from sqlalchemy import MetaData, Table\n",
    "metadata = MetaData()\n",
    "census = Table('census', metadata, autoload=True, autoload_with=engine)\n",
    "print(repr(census))\n",
    "\n",
    "Out:\n",
    "Table('census', MetaData(bind=None), Column('state',\n",
    "VARCHAR(length=30), table=<census>), Column('sex',\n",
    "VARCHAR(length=1), table=<census>), Column('age', INTEGER(),\n",
    "table=<census>), Column('pop2000', INTEGER(), table=<census>),\n",
    "Column('pop2008', INTEGER(), table=<census>), schema=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Engines and Connection Strings\n",
    "\n",
    "Alright, it's time to create your first engine! An engine is just a common interface to a database, and the information it requires to connect to one is contained in a connection string, such as **sqlite:///census_nyc.sqlite**. Here, **sqlite** is the database driver, while **census_nyc.sqlite** is a SQLite file contained in the local directory.\n",
    "\n",
    "You can learn a lot more about connection strings in the [SQLAlchemy documentation](https://docs.sqlalchemy.org/en/20/core/engines.html#database-urls).\n",
    "\n",
    "Your job in this exercise is to create an engine that connects to a local SQLite file named **census.sqlite**. Then, print the names of the tables it contains using the **.table_names()** method. Note that when you just want to print the table names, you do not need to use **engine.connect()** after creating the engine.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Import **create_engine** from the **sqlalchemy** module.\n",
    "* Using the **create_engine()** function, create an engine for a local file named **census.sqlite** with **sqlite** as the driver. Be sure to enclose the connection string within quotation marks.\n",
    "* Print the output from the **.table_names()** method on the **engine**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import create_engine - at top of notebook\n",
    "\n",
    "# Create an engine that connects to the census.sqlite file: engine\n",
    "engine = create_engine(census_sql_data)\n",
    "\n",
    "# Create an inspector object\n",
    "inspector = inspect(engine)\n",
    "\n",
    "# Use the inspector to list the table names\n",
    "table_names = inspector.get_table_names()\n",
    "print(table_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autoloading Tables from a Database\n",
    "\n",
    "SQLAlchemy can be used to automatically load tables from a database using something called reflection. Reflection is the process of reading the database and building the metadata based on that information. It's the opposite of creating a Table by hand and is very useful for working with existing databases. To perform reflection, you need to import the **Table** object from the SQLAlchemy package. Then, you use this **Table** object to read your table from the engine and autoload the columns. Using the **Table** object in this manner is a lot like passing arguments to a function. For example, to autoload the columns with the engine, you have to specify the keyword arguments **autoload=True** and **autoload_with=engine** to **Table()**.\n",
    "\n",
    "In this exercise, your job is to reflect the **census** table available on your **engine** into a variable called **census**. The metadata has already been loaded for you using **MetaData()** and is available in the variable **metadata**.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Import the **Table** object from **sqlalchemy**.\n",
    "* Reflect the **census** table by using the Table object with the arguments:\n",
    "    * The name of the table as a string (**'census'**).\n",
    "    * The metadata, contained in the variable **metadata**.\n",
    "    * **autoload=True**\n",
    "    * The engine to autoload with - in this case, **engine**.\n",
    "* Print the details of **census** using the **repr()** function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2024-04-19 Update Notes**\n",
    "\n",
    "The error you're seeing in the updated trace is due to the use of deprecated arguments with the `Table` constructor in SQLAlchemy version 1.4 and later. The `autoload` and `autoload_with` parameters have been replaced by a different mechanism for reflecting tables from a database. \n",
    "\n",
    "To fix the error, you should use the `autoload_with` parameter in a different way along with SQLAlchemy's reflection system.\n",
    "\n",
    "This code first reflects all tables from the connected database into the metadata object with `metadata.reflect(engine)`. Then, it retrieves a specific table (in this case, 'census') without using the now-deprecated `autoload` parameter. This approach uses the recommended pattern for SQLAlchemy version 1.4 and later, providing compatibility and future-proofing your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Table - at top of Notebook\n",
    "\n",
    "# Create a MetaData instance\n",
    "metadata = MetaData()\n",
    "\n",
    "# Reflect an existing table by using the Table constructor and MetaData.reflect\n",
    "metadata.reflect(engine)\n",
    "census = Table('census', metadata, autoload_with=engine)\n",
    "\n",
    "# Now you can print out the structure of the table\n",
    "print(repr(census))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewing Table Details\n",
    "\n",
    "Great job reflecting the **census** table! Now you can begin to learn more about the columns and structure of your table. It is important to get an understanding of your database by examining the column names. This can be done by using the **.columns** attribute and accessing the **.keys()** method. For example, **census.columns.keys()** would return a list of column names of the **census** table.\n",
    "\n",
    "Following this, we can use the metadata container to find out more details about the reflected table such as the columns and their types. For example, table objects are stored in the **metadata.tables** dictionary, so you can get the metadata of your **census** table with **metadata.tables['census']**. This is similar to your use of the **repr()** function on the census table from the previous exercise.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Reflect the **census** table as you did in the previous exercise using the **Table()** function.\n",
    "* Print a list of column names of the **census** table by applying the **.keys()** method to **census.columns**.\n",
    "* Print the details of the **census** table using the **metadata.tables** dictionary along with the **repr()** function. To do this, first access the **'census'** key of the **metadata.tables** dictionary, and place this inside the provided **repr()** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reflect the census table from the engine: census\n",
    "census = Table('census', metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "# Print the column names\n",
    "census.columns.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print full table metadata\n",
    "repr(metadata.tables['census'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQL Statements\n",
    "\n",
    "* Select, Insert, Update & Delete data\n",
    "* Create & Alter data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic SQL querying\n",
    "\n",
    "```sql\n",
    "● SELECT column_name FROM table_name\n",
    "● SELECT pop2008 FROM People\n",
    "● SELECT * FROM People\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic SQL querying\n",
    "\n",
    "```python\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///census_nyc.sqlite')\n",
    "connection = engine.connect()\n",
    "stmt = 'SELECT * FROM people'\n",
    "result_proxy = connection.execute(stmt)\n",
    "results = result_proxy.fetchall()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResultProxy vs ResultSet\n",
    "\n",
    "```python\n",
    "In [5]: result_proxy = connection.execute(stmt)\n",
    "In [6]: results = result_proxy.fetchall()\n",
    "```\n",
    "\n",
    "* ResultProxy\n",
    "* ResultSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling ResultSets\n",
    "\n",
    "```python\n",
    "first_row = results[0]\n",
    "print(first_row)\n",
    "Out: ('Illinois', 'M', 0, 89600, 95012)\n",
    "\n",
    "print(first_row.keys())\n",
    "Out: ['state', 'sex', 'age', 'pop2000', 'pop2008']\n",
    "\n",
    "print(first_row.state)\n",
    "Out: 'Illinois'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQLAlchemy to Build Queries\n",
    "\n",
    "* Provides a **<font color=purple><u>Pythonic</u></font>** way to build SQL statements\n",
    "* Hides differences between backend database types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQLAlchemy querying\n",
    "\n",
    "```python\n",
    "from sqlalchemy import Table, MetaData\n",
    "metadata = MetaData()\n",
    "census = Table('census', metadata, autoload=True, autoload_with=engine)\n",
    "stmt = select(census)\n",
    "results = connection.execute(stmt).fetchall()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQLAlchemy Select Statement\n",
    "\n",
    "* Requires a list of one or more Tables or Columns\n",
    "* Using a table will select all the columns in it\n",
    "\n",
    "```python\n",
    "stmt = select(census)\n",
    "print(stmt)\n",
    "Out: 'SELECT * from CENSUS'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting data from a Table: raw SQL\n",
    "\n",
    "Using what we just learned about SQL and applying the **.execute()** method on our connection, we can leverage a raw SQL query to query all the records in our **census** table. The object returned by the **.execute()** method is a **ResultProxy**. On this ResultProxy, we can then use the **.fetchall()** method to get our results - that is, the **ResultSet**.\n",
    "\n",
    "In this exercise, you'll use a traditional SQL query. In the next exercise, you'll move to SQLAlchemy and begin to understand its advantages. Go for it!\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Build a SQL statement to query all the columns from **census** and store it in **stmt**. Note that your SQL statement must be a string.\n",
    "* Use the **.execute()** and **.fetchall()** methods on **connection** and store the result in **results**. Remember that **.execute()** comes before **.fetchall()** and that **stmt** needs to be passed to **.execute()**.\n",
    "* Print **results**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2024-04-22 Update Notes**\n",
    "\n",
    "SQLAlchemy in its later versions (especially from version 1.4 onwards) requires that you wrap raw SQL strings in a `text()` construct to safely execute them. This is a part of SQLAlchemy's security measures to help prevent SQL injection attacks.\n",
    "\n",
    "In this revised code, `text()` is imported from `sqlalchemy` and is used to wrap the SQL statement. This ensures that SQLAlchemy treats the string as an SQL expression, allowing it to be executed on the database. This method is safe and recommended when executing raw SQL queries with SQLAlchemy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(census_sql_data)\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build select statement for census table: stmt\n",
    "stmt = text('SELECT * FROM census')\n",
    "\n",
    "# Execute the statement and fetch the results: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "results[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting data from a Table with SQLAlchemy\n",
    "\n",
    "It's now time to build your first select statement using SQLAlchemy. SQLAlchemy provides a nice \"Pythonic\" way of interacting with databases. So rather than dealing with the differences between specific dialects of traditional SQL such as MySQL or PostgreSQL, you can leverage the Pythonic framework of SQLAlchemy to streamline your workflow and more efficiently query your data. For this reason, it is worth learning even if you may already be familiar with traditional SQL.\n",
    "\n",
    "In this exercise, you'll once again build a statement to query all records from the **census** table. This time, however, you'll make use of the **select()** function of the **sqlalchemy** module. This function requires a list of tables or columns as the only required argument.\n",
    "\n",
    "**Table** and **MetaData** have already been imported. The **metadata** is available as metadata and the connection to the database as **connection**.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Import **select** from the **sqlalchemy** module.\n",
    "* Reflect the **census** table. This code is already written for you.\n",
    "* Create a query using the **select()** function to retrieve the **census** table. To do so, pass a list to **select()** containing a single element: **census**.\n",
    "* Print **stmt** to see the actual SQL query being created. This code has been written for you.\n",
    "* Using the provided **print()** function, print all the records from the **census** table. To do this:\n",
    "    * Use the **.execute()** method on **connection** with **stmt** as the argument to retrieve the ResultProxy.\n",
    "    * Use **.fetchall()** on **connection.execute(stmt)** to retrieve the ResultSet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2024-04-22 Update Note**\n",
    "\n",
    "The `select` function from SQLAlchemy no longer accepts a list of tables or columns as an argument inside a list. This syntax change was introduced in SQLAlchemy 1.4 to enforce more explicit construction patterns and improve security against SQL injection attacks.\n",
    "\n",
    "This change reflects the updated usage of the `select` function where you pass the table or columns directly, without enclosing them in brackets. This update in your code will conform to the latest SQLAlchemy syntax and should run without errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import select - at top of Notebook\n",
    "\n",
    "engine = create_engine(census_sql_data)\n",
    "connection = engine.connect()\n",
    "metadata = MetaData()\n",
    "metadata.reflect(engine)\n",
    "\n",
    "# Access the 'census' table\n",
    "census = metadata.tables['census']\n",
    "\n",
    "# Build select statement for census table: stmt\n",
    "stmt = select(census)\n",
    "\n",
    "# Print the emitted statement to see the SQL emitted\n",
    "print(stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the statement and print the results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "results[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling a ResultSet\n",
    "\n",
    "Recall the differences between a ResultProxy and a ResultSet:\n",
    "\n",
    "* ResultProxy: The object returned by the **.execute()** method. It can be used in a variety of ways to get the data returned by the query.\n",
    "* ResultSet: The actual data asked for in the query when using a fetch method such as **.fetchall()** on a ResultProxy.\n",
    "\n",
    "This separation between the ResultSet and ResultProxy allows us to fetch as much or as little data as we desire.\n",
    "\n",
    "Once we have a ResultSet, we can use Python to access all the data within it by column name and by list style indexes. For example, you can get the first row of the results by using **results[0]**. With that first row then assigned to a variable **first_row**, you can get data from the first column by either using **first_row[0]** or by column name such as **first_row['column_name']**. You'll now practice exactly this using the ResultSet you obtained from the **census** table in the previous exercise. It is stored in the variable **results**. Enjoy!\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Extract the first row of **results** and assign it to the variable **first_row**.\n",
    "* Print the value of the first column in **first_row**.\n",
    "* Print the value of the **'state'** column in **first_row**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first row of the results by using an index: first_row\n",
    "first_row = results[0]\n",
    "\n",
    "# Print the first row of the results\n",
    "print(first_row)\n",
    "\n",
    "# Print the first column of the first row by using an index\n",
    "print(first_row[0])\n",
    "\n",
    "# Print the 'state' column of the first row by using its name\n",
    "# print(first_row['state'])  # this does not work\n",
    "\n",
    "# attribute access does work\n",
    "print(first_row.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an SQLAlchemy Engine instance. This engine manages connections to the database.\n",
    "# The `census_sql_data` should be a database URL that specifies database dialect and connection arguments.\n",
    "engine = create_engine(census_sql_data)\n",
    "\n",
    "# Create a session. This session establishes and maintains all conversations with the database.\n",
    "# It represents a 'holding zone' for all the objects which you've loaded or associated with it during its lifespan.\n",
    "session = Session(bind=engine)\n",
    "\n",
    "# Create a MetaData instance. MetaData is a container object that keeps together many different features of a database (or multiple databases).\n",
    "metadata = MetaData()\n",
    "\n",
    "# Reflect the database schema into MetaData. This loads table definitions from the database automatically.\n",
    "# The `bind=engine` argument tells MetaData which engine to use for connection.\n",
    "metadata.reflect(bind=engine)\n",
    "\n",
    "# Access the 'census' table object from the metadata. This dictionary-style access allows you to get a Table object.\n",
    "# Each Table object is a member of the MetaData collection.\n",
    "census = metadata.tables['census']\n",
    "\n",
    "# Build a SELECT statement. `select(census)` constructs a simple query that selects all columns from the 'census' table.\n",
    "stmt = select(census)\n",
    "\n",
    "# Execute the SELECT statement using the session. This sends the SQL statement to the database and returns a result object.\n",
    "result = session.execute(stmt)\n",
    "\n",
    "# Fetch the first row of the result. `fetchone()` retrieves the next row of a query result set, returning a single sequence, or None if no more rows are available.\n",
    "first_row = result.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the type of the first row to verify it's an instance of `Row`, which allows both indexed and keyed access.\n",
    "print(type(first_row))\n",
    "\n",
    "# Print the column names available in the result. This helps verify the structure of the returned rows and what columns can be accessed.\n",
    "print(result.keys())\n",
    "\n",
    "# Print the first row to see the data that has been fetched.\n",
    "print(first_row)\n",
    "\n",
    "# Print the value of the 'state' column accessed using attribute access. This is an alternative access method provided by SQLAlchemy for convenience.\n",
    "print(first_row.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coming up Next...\n",
    "\n",
    "* Beef up your SQL querying skills\n",
    "* Learn how to extract all types of useful information from your databases using SQLAlchemy\n",
    "* Learn how to crete and write to relational databases\n",
    "* Deep dive into the US census dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Filtering, Ordering and Grouping to Queries\n",
    "\n",
    "In this chapter, you will build on the database knowledge you began acquiring in the previous chapter by writing more nuanced queries that allow you to filter, order, and count your data, all within the Pythonic framework provided by SQLAlchemy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering and Targeted Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Where Clauses\n",
    "\n",
    "```python\n",
    "stmt = select(census)\n",
    "stmt = stmt.where(census.columns.state == 'California')\n",
    "results = connection.execute(stmt).fetchall()\n",
    "for result in results:\n",
    "    print(result.state, result.age)\n",
    "    \n",
    "Out:\n",
    "California 0\n",
    "California 1\n",
    "California 2\n",
    "California 3\n",
    "California 4\n",
    "Calif\n",
    "```\n",
    "\n",
    "* Restrict data returned by a query based on boolean conditions\n",
    "* Compare a column against a value or another column\n",
    "* Often used comparisons: '==', '<=', '>=', or '!='"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expressions\n",
    "\n",
    "* Provide more complex conditions than simple operators\n",
    "* Eg. in_(), like(), between()\n",
    "* Many more in documentation\n",
    "* Available as method on a Column\n",
    "\n",
    "```python\n",
    "stmt = select(census)\n",
    "stmt = stmt.where(census.columns.state.startswith('New'))\n",
    "for result in connection.execute(stmt):\n",
    "    print(result.state, result.pop2000)\n",
    "\n",
    "Out:\n",
    "New Jersey 56983\n",
    "New Jersey 56686\n",
    "New Jersey 57011\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conjunctions\n",
    "\n",
    "* Allow us to have multiple criteria in a where clause\n",
    "* Eg. and_(), not_(), or_()\n",
    "\n",
    "```python\n",
    "from sqlalchemy import or_\n",
    "stmt = select(census)\n",
    "stmt = stmt.where(or_(census.columns.state == 'California',\n",
    "                      census.columns.state == 'New York'))\n",
    "for result in connection.execute(stmt):\n",
    "    print(result.state, result.sex)\n",
    "    \n",
    "Out:\n",
    "New York M\n",
    "…\n",
    "California F\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### onnecting to a PostgreSQL Database\n",
    "\n",
    "In these exercises, you will be working with real databases hosted on the cloud via Amazon Web Services (AWS)!\n",
    "\n",
    "Let's begin by connecting to a PostgreSQL database. When connecting to a PostgreSQL database, many prefer to use the psycopg2 database driver as it supports practically all of PostgreSQL's features efficiently and is the standard dialect for PostgreSQL in SQLAlchemy.\n",
    "\n",
    "You might recall from Chapter 1 that we use the **create_engine()** function and a connection string to connect to a database.\n",
    "\n",
    "There are three components to the connection string in this exercise: the dialect and driver (**'postgresql+psycopg2://'**), followed by the username and password (**'student:datacamp'**), followed by the host and port **('@postgresql.csrrinzqubik.us-east-1.rds.amazonaws.com:5432/')**, and finally, the database name (**'census'**). You will have to pass this string as an argument to **create_engine()** in order to connect to the database.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Import **create_engine** from **sqlalchemy**.\n",
    "* Create an engine to the **census** database by concatenating the following strings:\n",
    "    * **'postgresql+psycopg2://'**\n",
    "    * **'student:datacamp'**\n",
    "    * '@postgresql.csrrinzqubik.us-east-1.rds.amazonaws.com'\n",
    "    * **':5432/census'**\n",
    "* Use the **.table_names()** method on **engine** to print the table names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use with local file\n",
    "engine = create_engine(census_sql_data)\n",
    "connection = engine.connect()\n",
    "metadata = MetaData()\n",
    "metadata.reflect(bind=engine)\n",
    "\n",
    "census = metadata.tables['census']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an inspector object from the engine\n",
    "inspector = inspect(engine)\n",
    "\n",
    "# Use the inspector to list the table names\n",
    "table_names = inspector.get_table_names()\n",
    "print(table_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an engine to the census database - exercise\n",
    "# engine = create_engine('postgresql+psycopg2://student:datacamp@postgresql.csrrinzqubik.us-east-1.rds.amazonaws.com:5432/census')\n",
    "\n",
    "# Use the .table_names() method on the engine to print the table names\n",
    "# print(engine.table_names())  # this no longer works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter data selected from a Table - Simple\n",
    "\n",
    "Having connected to the database, it's now time to practice filtering your queries!\n",
    "\n",
    "As mentioned in the video, a **where()** clause is used to filter the data that a statement returns. For example, to select all the records from the **census** table where the sex is Female (or **'F'**) we would do the following:\n",
    "\n",
    "**select(census).where(census.columns.sex == 'F')**\n",
    "\n",
    "In addition to **==** we can use basically any python comparison operator (such as **<=**, **!=**, etc) in the **where()** clause.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Select all records from the census table by passing in **census** as a list to **select()**.\n",
    "* Append a where clause to **stmt** to return only the records with a **state** of **'New York'**.\n",
    "* Execute the statement **stmt** using **.execute()** and retrieve the results using **.fetchall()**.\n",
    "* Iterate over **results** and print the **age**, **sex** and **pop2008** columns from each record. For example, you can print out the **age** of **result** with **result.age**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a select query: stmt\n",
    "stmt = select(census)\n",
    "\n",
    "# Add a where clause to filter the results to only those for New York\n",
    "stmt = stmt.where(census.columns.state == 'New York')\n",
    "\n",
    "# Execute the query to retrieve all the data returned: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Loop over the results and print the age, sex, and pop2008\n",
    "for i, result in enumerate(results):\n",
    "    if i < 7:\n",
    "        print(result.age, result.sex, result.pop2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter data selected from a Table - Expressions\n",
    "\n",
    "In addition to standard Python comparators, we can also use methods such as **in_()** to create more powerful **where()** clauses. You can see a full list of expressions in the [SQLAlchemy Documentation](https://docs.sqlalchemy.org/en/20/core/sqlelement.html#module-sqlalchemy.sql.expression).\n",
    "\n",
    "We've already created a list of some of the most densely populated states.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Select all records from the **census** table by passing it in as a list to **select()**.\n",
    "* Append a where clause to return all the records with a **state** in the **states** list. Use **in_(states)** on **census.columns.state** to do this.\n",
    "* Loop over the ResultProxy **connection.execute(stmt)** and print the **state** and **pop2000** columns from each record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = stmt.where(census.columns.state.startswith('New'))\n",
    "for result in connection.execute(stmt):\n",
    "    print(result.state, result.pop2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['New York', 'California', 'Texas']\n",
    "\n",
    "# Create a query for the census table: stmt\n",
    "stmt = select(census)\n",
    "\n",
    "# Append a where clause to match all the states in_ the list states\n",
    "stmt = stmt.where(census.columns.state.in_(states))\n",
    "\n",
    "# Loop over the ResultProxy and print the state and its population in 2000\n",
    "for i, result in enumerate(connection.execute(stmt)):\n",
    "    if i < 7:\n",
    "        print(result.state, result.pop2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter data selected from a Table - Advanced\n",
    "\n",
    "You're really getting the hang of this! SQLAlchemy also allows users to use conjunctions such as **and_()**, **or_()**, and **not_()** to build more complex filtering. For example, we can get a set of records for people in New York who are 21 or 37 years old with the following code:\n",
    "\n",
    "```python\n",
    "select(census).where(and_(census.columns.state == 'New York',\n",
    "                            or_(census.columns.age == 21,\n",
    "                                census.columns.age == 37)))\n",
    "```\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Import **and_** from the **sqlalchemy** module.\n",
    "* Select all records from the **census** table.\n",
    "* Append a where clause to filter all the records whose **state** is **'California'**, and whose **sex** is not **'M'**.\n",
    "* Iterate over the ResultProxy and print the **age** and **sex** columns from each record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a query for the census table: stmt\n",
    "stmt = select(census)\n",
    "\n",
    "# Append a where clause to select only non-male records from California using and_\n",
    "# The state of California with a non-male sex\n",
    "stmt = stmt.where(and_(census.columns.state == 'California',\n",
    "                       census.columns.sex != 'M'))\n",
    "\n",
    "# Loop over the ResultProxy printing the age and sex\n",
    "for i, result in enumerate(connection.execute(stmt)):\n",
    "    if i < 7:\n",
    "        print(result.age, result.sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordering Query Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order by Clauses\n",
    "\n",
    "* Allows us to control the order in which records are returned in the query results\n",
    "* Available as a method on statements order_by()\n",
    "\n",
    "```python\n",
    "print(results[:10])\n",
    "Out: [('Illinois',), …]\n",
    "\n",
    "stmt = select(census.columns.state)\n",
    "stmt = stmt.order_by(census.columns.state)\n",
    "results = connection.execute(stmt).fetchall()\n",
    "print(results[:10])\n",
    "Out: [('Alabama',), …]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order by Descending\n",
    "\n",
    "* Wrap the column with desc() in the order_by() clause"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order by Multiple\n",
    "\n",
    "* Just separate multiple columns with a comma\n",
    "* Orders completely by the first column\n",
    "* Then if there are duplicates in the first column, orders by the second column\n",
    "* repeat until all columns are ordered\n",
    "\n",
    "```python\n",
    "print(results)\n",
    "Out:\n",
    "('Alabama', 'M')\n",
    "\n",
    "stmt = select(census.columns.state, census.columns.sex)\n",
    "stmt = stmt.order_by(census.columns.state, census.columns.sex)\n",
    "results = connection.execute(stmt).first()\n",
    "print(results)\n",
    "\n",
    "Out:\n",
    "('Alabama', 'F')\n",
    "('Alabama', 'F')\n",
    "…\n",
    "('Alabama', 'M')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use with local file\n",
    "engine = create_engine(census_sql_data)\n",
    "connection = engine.connect()\n",
    "metadata = MetaData()\n",
    "metadata.reflect(engine)\n",
    "\n",
    "# Reflect the 'census' table via engine\n",
    "census = Table('census', metadata, autoload_with=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordering by a Single Column\n",
    "\n",
    "To sort the result output by a field, we use the **.order_by()** method. By default, the **.order_by()** method sorts from lowest to highest on the supplied column. You just have to pass in the name of the column you want sorted to **.order_by()**.\n",
    "\n",
    "In the video, for example, Jason used **stmt.order_by(census.columns.state)** to sort the result output by the **state** column.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Select all records of the **state** column from the **census** table. To do this, pass **census.columns.state** as a list to **select()**.\n",
    "* Append an **.order_by()** to sort the result output by the **state** column.\n",
    "* Execute **stmt** using the **.execute()** method on **connection** and retrieve all the results using **.fetchall()**.\n",
    "* Print the first 10 rows of **results**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a query to select the state column: stmt\n",
    "stmt = select(census.columns.state)\n",
    "\n",
    "# Order stmt by the state column\n",
    "stmt = stmt.order_by(census.columns.state)\n",
    "\n",
    "# Execute the query and store the results: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print the first 10 results\n",
    "results[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordering in Descending Order by a Single Column\n",
    "\n",
    "You can also use **.order_by()** to sort from highest to lowest by wrapping a column in the **desc()** function. Although you haven't seen this function in action, it generalizes what you have already learned.\n",
    "\n",
    "Pass **desc()** (for \"descending\") inside an **.order_by()** with the name of the column you want to sort by. For instance, **stmt.order_by(desc(table.columns.column_name))** sorts **column_name** in descending order.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Import **desc** from the **sqlalchemy** module.\n",
    "* Select all records of the **state** column from the **census** table.\n",
    "* Append an **.order_by()** to sort the result output by the **state** column in **descending** order. Save the result as **rev_stmt**.\n",
    "* Execute **rev_stmt** using **connection.execute()** and fetch all the results with **.fetchall()**. Save them as **rev_results**.\n",
    "* Print the first 10 rows of **rev_results**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a query to select the state column: stmt\n",
    "stmt = select(census.columns.state)\n",
    "\n",
    "# Order stmt by state in descending order: rev_stmt\n",
    "rev_stmt = stmt.order_by(desc(census.columns.state))\n",
    "\n",
    "# Execute the query and store the results: rev_results\n",
    "rev_results = connection.execute(rev_stmt).fetchall()\n",
    "\n",
    "# Print the first 10 rev_results\n",
    "rev_results[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordering by Multiple Columns\n",
    "\n",
    "We can pass multiple arguments to the **.order_by()** method to order by multiple columns. In fact, we can also sort in ascending or descending order for each individual column. Each column in the **.order_by()** method is fully sorted from left to right. This means that the first column is completely sorted, and then within each matching group of values in the first column, it's sorted by the next column in the **.order_by()** method. This process is repeated until all the columns in the **.order_by()** are sorted.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Select all records of the **state** and **age** columns from the **census** table.\n",
    "* Use **.order_by()** to sort the output of the **state** column in ascending order and **age** in descending order. (NOTE: **desc** is already imported).\n",
    "* Execute **stmt** using the **.execute()** method on **connection** and retrieve all the results using **.fetchall()**.\n",
    "* Print the first 20 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a query to select state and age: stmt\n",
    "stmt = select(census.columns.state, census.columns.age)\n",
    "\n",
    "# Append order by to ascend by state and descend by age\n",
    "stmt = stmt.order_by(census.columns.state, desc(census.columns.age))\n",
    "\n",
    "# Execute the statement and store all the records: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print the first 20 results\n",
    "results[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting, Summing and Grouping Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQL Functions\n",
    "\n",
    "* E.g. Count, Sum\n",
    "* from sqlalchemy import func\n",
    "* More efficient than processing in Python\n",
    "* Aggregate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sum Example\n",
    "\n",
    "```python\n",
    "from sqlalchemy import func\n",
    "stmt = select(func.sum(census.columns.pop2008))\n",
    "results = connection.execute(stmt).scalar()\n",
    "print(results)\n",
    "Out: 302876613\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group by\n",
    "\n",
    "* Allows us to group row by common values\n",
    "\n",
    "```python\n",
    "stmt = select(census.columns.sex, func.sum(census.columns.pop2008))\n",
    "stmt = stmt.group_by(census.columns.sex)\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "print(results)\n",
    "Out: [('F', 153959198), ('M', 148917415)]\n",
    "```\n",
    "\n",
    "* Supports multiple columns to group by with a pattern similar to order_by()\n",
    "* Requires all selected columns to be grouped or aggregated by a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group by Multiple\n",
    "\n",
    "```python\n",
    "stmt = select(census.columns.sex, census.columns.age, func.sum(census.columns.pop2008))\n",
    "stmt = stmt.group_by(census.columns.sex, census.columns.age)\n",
    "results = connection.execute(stmt).fetchall()\n",
    "print(results)\n",
    "\n",
    "Out:\n",
    "[('F', 0, 2105442), ('F', 1, 2087705), ('F', 2, 2037280), ('F', 3,\n",
    "2012742), ('F', 4, 2014825), ('F', 5, 1991082), ('F', 6, 1977923),\n",
    "('F', 7, 2005470), ('F', 8, 1925725), …\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling ResultSets from Functions\n",
    "\n",
    "* SQLAlchemy auto generates “column names” for functions in the ResultSet\n",
    "* The column names are often func_# such as count_1\n",
    "* Replace them with the label() method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using label()\n",
    "\n",
    "```python\n",
    "print(results[0].keys())\n",
    "Out: ['sex', u'sum_1']\n",
    "\n",
    "stmt = select(census.columns.sex, func.sum(census.columns.pop2008).label( 'pop2008_sum'))\n",
    "stmt = stmt.group_by(census.columns.sex)\n",
    "results = connection.execute(stmt).fetchall()\n",
    "print(results[0].keys())\n",
    "Out: ['sex', 'pop2008_sum']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use with local file\n",
    "engine = create_engine(census_sql_data)\n",
    "connection = engine.connect()\n",
    "metadata = MetaData()\n",
    "metadata.reflect(engine)\n",
    "\n",
    "# Reflect the 'census' table via engine\n",
    "census = Table('census', metadata, autoload_with=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting Distinct Data\n",
    "\n",
    "As mentioned in the video, SQLAlchemy's **func** module provides access to built-in SQL functions that can make operations like counting and summing faster and more efficient.\n",
    "\n",
    "In the video, Jason used **func.sum()** to get a **sum** of the **pop2008** column of **census** as shown below:\n",
    "\n",
    "```python\n",
    "select(func.sum(census.columns.pop2008))\n",
    "```\n",
    "\n",
    "If instead you want to **count** the number of values in **pop2008**, you could use **func.count()** like this:\n",
    "\n",
    "```python\n",
    "select(func.count(census.columns.pop2008))\n",
    "```\n",
    "\n",
    "Furthermore, if you only want to count the **distinct** values of **pop2008**, you can use the **.distinct()** method:\n",
    "\n",
    "```python\n",
    "select(func.count(census.columns.pop2008.distinct()))\n",
    "```\n",
    "\n",
    "In this exercise, you will practice using **func.count()** and **.distinct()** to get a count of the distinct number of states in **census**.\n",
    "\n",
    "So far, you've seen **.fetchall()** and **.first()** used on a ResultProxy to get the results. The ResultProxy also has a method called **.scalar()** for getting just the value of a query that returns only one row and column.\n",
    "\n",
    "This can be very useful when you are querying for just a count or sum.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Build a **select** statement to **count** the **distinct** values in the **state** field of **census**.\n",
    "* Execute **stmt** to get the count and store the results as **distinct_state_count**.\n",
    "* Print the value of **distinct_state_count**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a query to count the distinct states values: stmt\n",
    "stmt = select(func.count(census.columns.state.distinct()))\n",
    "\n",
    "# Execute the query and store the scalar result: distinct_state_count\n",
    "distinct_state_count = connection.execute(stmt).scalar()\n",
    "\n",
    "# Print the distinct_state_count\n",
    "distinct_state_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count of Records by State\n",
    "\n",
    "Often, we want to get a count for each record with a particular value in another column. The **.group_by()** method helps answer this type of query. You can pass a column to the **.group_by()** method and use in an aggregate function like **sum()** or **count()**. Much like the **.order_by()** method, **.group_by()** can take multiple columns as arguments.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Import **func** from **sqlalchemy**.\n",
    "* Build a **select** statement to get the value of the state field and a count of the values in the **age** field, and store it as **stmt**.\n",
    "* Use the **.group_by()** method to group the statement by the **state** column.\n",
    "* Execute **stmt** using the **connection** to get the count and store the results as **results**.\n",
    "* Print the keys/column names of the results returned using **results[0].keys()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an SQLAlchemy Engine instance. This engine manages connections to the database.\n",
    "# The `census_sql_data` should be a database URL that specifies database dialect and connection arguments.\n",
    "engine = create_engine(census_sql_data)\n",
    "\n",
    "# Create a session. This session establishes and maintains all conversations with the database.\n",
    "# It represents a 'holding zone' for all the objects which you've loaded or associated with it during its lifespan.\n",
    "session = Session(bind=engine)\n",
    "\n",
    "# Create a MetaData instance. MetaData is a container object that keeps together many different features of a database (or multiple databases).\n",
    "metadata = MetaData()\n",
    "\n",
    "# Reflect the database schema into MetaData. This loads table definitions from the database automatically.\n",
    "# The `bind=engine` argument tells MetaData which engine to use for connection.\n",
    "metadata.reflect(bind=engine)\n",
    "\n",
    "# Access the 'census' table object from the metadata. This dictionary-style access allows you to get a Table object.\n",
    "# Each Table object is a member of the MetaData collection.\n",
    "census = metadata.tables['census']\n",
    "\n",
    "# Build a SELECT statement. `select(census)` constructs a simple query that selects all columns from the 'census' table.\n",
    "stmt = select(census.columns.state, func.count(census.columns.age))\n",
    "\n",
    "# Group stmt by state\n",
    "stmt = stmt.group_by(census.columns.state)\n",
    "\n",
    "# Execute the SELECT statement using the session. This sends the SQL statement to the database and returns a result object.\n",
    "result = session.execute(stmt)\n",
    "\n",
    "rows = result.fetchall()\n",
    "\n",
    "# Fetch the first row of the result. `fetchone()` retrieves the next row of a query result set, returning a single sequence, or None if no more rows are available.\n",
    "first_row = rows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the column names available in the result. This helps verify the structure of the returned rows and what columns can be accessed.\n",
    "print(result.keys())\n",
    "\n",
    "# Print some rows\n",
    "print(rows[:5])\n",
    "\n",
    "# Print the type of the first row to verify it's an instance of `Row`, which allows both indexed and keyed access.\n",
    "print(type(first_row))\n",
    "\n",
    "print(first_row.state)\n",
    "print(first_row.count_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`result = session.execute(stmt)` is not the same as `result = connection.execute(stmt).fetchall()`\n",
    "\n",
    "`type(session.execute(stmt))` → `sqlalchemy.engine.cursor.CursorResult`\n",
    "\n",
    "`type(connection.execute(stmt).fetchall())` → `list`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining the Population Sum by State\n",
    "\n",
    "To avoid confusion with query result column names like **count_1**, we can use the **.label()** method to provide a name for the resulting column. This gets appendedto the function method we are using, and its argument is the name we want to use.\n",
    "\n",
    "We can pair **func.sum()** with **.group_by()** to get a sum of the population by **State** and use the **label()** method to name the output.\n",
    "\n",
    "We can also create the **func.sum()** expression before using it in the select statement. We do it the same way we would inside the select statement and store it in a variable. Then we use that variable in the select statement where the **func.sum()** would normally be.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Import **func** from **sqlalchemy**.\n",
    "* Build an expression to calculate the sum of the values in the **pop2008** field labeled as **'population'**.\n",
    "* Build a select statement to get the value of the **state** field and the sum of the values in **pop2008**.\n",
    "* Group the statement by **state** using a **.group_by()** method.\n",
    "* Execute **stmt** using the **connection** to get the count and store the results as **results**.\n",
    "* Print the keys/column names of the results returned using **results[0].keys()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an expression to calculate the sum of pop2008 labeled as population\n",
    "pop2008_sum = func.sum(census.columns.pop2008).label('population')\n",
    "\n",
    "# Build a query to select the state and sum of pop2008: stmt\n",
    "stmt = select(census.columns.state, pop2008_sum)\n",
    "\n",
    "# Group stmt by state\n",
    "stmt = stmt.group_by(census.columns.state)\n",
    "\n",
    "# Execute the statement and store all the records: results\n",
    "results = connection.execute(stmt)\n",
    "\n",
    "# Print the keys/column names of the results returned\n",
    "print(results.keys())\n",
    "\n",
    "rows = results.fetchall()\n",
    "\n",
    "# Print results\n",
    "rows[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQLAlchemy and Pandas for Visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQLAlchemy and Pandas\n",
    "\n",
    "* DataFrame can take a SQLAlchemy ResultSet\n",
    "* Make sure to set the DataFrame columns to the ResultSet keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame Example\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "df.columns = results[0].keys()\n",
    "print(df)\n",
    "\n",
    "Out:\n",
    "sex pop2008_sum\n",
    "0 F 2105442\n",
    "1 F 2087705\n",
    "2 F 2037280\n",
    "3 F 2012742\n",
    "4 F 2014825\n",
    "5 F 1991082\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphing\n",
    "\n",
    "* We can graph just like we would normally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphing Example\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "df[10:20].plot.barh()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use with local file\n",
    "engine = create_engine(census_sql_data)\n",
    "connection = engine.connect()\n",
    "metadata = MetaData()\n",
    "metadata.reflect(bind=engine)\n",
    "census = metadata.tables['census']\n",
    "\n",
    "# Build an expression to calculate the sum of pop2008 labeled as population\n",
    "pop2008_sum = func.sum(census.columns.pop2008).label('population')\n",
    "\n",
    "# Build a query to select the state and sum of pop2008: stmt\n",
    "stmt = select(census.columns.state, pop2008_sum)\n",
    "\n",
    "stmt = stmt.order_by(desc(pop2008_sum))\n",
    "\n",
    "# Group stmt by state\n",
    "stmt = stmt.group_by(census.columns.state)\n",
    "\n",
    "# Execute the statement and store all the records: results\n",
    "results = connection.execute(stmt)\n",
    "\n",
    "rows = results.fetchall()\n",
    "\n",
    "# Print results\n",
    "rows[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQLAlchemy ResultsProxy and Pandas Dataframes\n",
    "\n",
    "We can feed a ResultProxy directly into a pandas DataFrame, which is the workhorse of many Data Scientists in PythonLand. Jason demonstrated this in the video. In this exercise, you'll follow exactly the same approach to convert a ResultProxy into a DataFrame.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Import **pandas** as **pd**.\n",
    "* Create a DataFrame **df** using **pd.DataFrame()** on the ResultProxy **results**.\n",
    "* Set the columns of the DataFrame **df.columns** to be the columns from the first result object **results[0].keys()**.\n",
    "* Print the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the results: df\n",
    "df = pd.DataFrame(rows, columns=results.keys())\n",
    "\n",
    "# Print the Dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From SQLAlchemy results to a Graph\n",
    "\n",
    "We can also take advantage of **pandas** and **Matplotlib** to build figures of our data. Remember that data visualization is essential for both exploratory data analysis and communication of your data!\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Import **matplotlib.pyplot** as **plt**.\n",
    "* Create a DataFrame **df** using **pd.DataFrame()** on the provided **results**.\n",
    "* Set the columns of the DataFrame **df.columns** to be the columns from the first result object **results[0].keys()**.\n",
    "* Print the DataFrame **df**.\n",
    "* Use the **plot.bar()** method on **df** to create a bar plot of the results.\n",
    "* Display the plot with **plt.show()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rows, columns=results.keys())\n",
    "\n",
    "# Print the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the DataFrame\n",
    "ax = df.plot(x='state', kind='barh', figsize=(7, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced SQLAlchemy Queries\n",
    "\n",
    "Herein, you will learn to perform advanced - and incredibly useful - queries that will enable you to interact with your data in powerful ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Values in a Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Math Operators\n",
    "\n",
    "* addition +\n",
    "* subtraction -\n",
    "* multiplication *\n",
    "* division /\n",
    "* modulus %\n",
    "* Work differently on different data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Difference\n",
    "\n",
    "```python\n",
    "stmt = select(census.columns.age, (census.columns.pop2008 - census.columns.pop2000).label('pop_change'))\n",
    "stmt = stmt.group_by(census.columns.age)\n",
    "stmt = stmt.order_by(desc('pop_change'))\n",
    "stmt = stmt.limit(5)\n",
    "results = connection.execute(stmt).fetchall()\n",
    "print(results)\n",
    "\n",
    "Out: [(61, 52672), (85, 51901), (54, 50808), (58, 45575), (60, 44915)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case Statement\n",
    "\n",
    "* Used to treat data differently based on a condition\n",
    "* Accepts a list of conditions to match and a column to return if the condition matches\n",
    "* The list of conditions ends with an else clause to determine what to do when a record doesn’t match any prior conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case Example\n",
    "\n",
    "```python\n",
    "from sqlalchemy import case\n",
    "stmt = select(func.sum(case((census.columns.state == 'New York', census.columns.pop2008), else_=0)))\n",
    "results = connection.execute(stmt).fetchall()\n",
    "print(results)\n",
    "\n",
    "Out:[(19465159,)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cast Statement\n",
    "\n",
    "* Converts data to another type\n",
    "* Useful for converting\n",
    "* integers to floats for division\n",
    "* strings to dates and times\n",
    "* Accepts a column or expression and the target Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percentage Example\n",
    "\n",
    "```python\n",
    "from sqlalchemy import case, cast, Float\n",
    "stmt = select((func.sum(case((census.columns.state == 'New York', census.columns.pop2008), else_=0)) /\n",
    "               cast(func.sum(census.columns.pop2008), Float) * 100).label('ny_percent'))\n",
    "results = connection.execute(stmt).fetchall()\n",
    "print(results)\n",
    "\n",
    "Out: [(Decimal('6.4267619765'),)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connecting to a MySQL Database\n",
    "\n",
    "Before you jump into the calculation exercises, let's begin by connecting to our database. Recall that in the last chapter you connected to a PostgreSQL database. Now, you'll connect to a MySQL database, for which many prefer to use the **pymysql** database driver, which, like **psycopg2** for PostgreSQL, you have to install prior to use.\n",
    "\n",
    "This connection string is going to start with **'mysql+pymysql://'**, indicating which dialect and driver you're using to establish the connection. The dialect block is followed by the **'username:password'** combo. Next, you specify the host and port with the following **'@host:port/'**. Finally, you wrap up the connection string with the **'database_name'**.\n",
    "\n",
    "Now you'll practice connecting to a MySQL database: it will be the same **census** database that you have already been working with. One of the great things about SQLAlchemy is that, after connecting, it abstracts over the type of database it has connected to and you can write the same SQLAlchemy code, regardless!\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Import the **create_engine** function from the **sqlalchemy** library.\n",
    "* Create an engine to the **census** database by concatenating the following strings and passing them to **create_engine()**:\n",
    "    * **'mysql+pymysql://'** (the dialect and driver).\n",
    "    * **'student:datacamp'** (the username and password).\n",
    "    * <b>'@courses.csrrinzqubik.us-east-1.rds.amazonaws.com:3306/'</b> (the host and port).\n",
    "    * **'census'** (the database name).\n",
    "* Use the **.table_names()** method on **engine** to print the table names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use with local file\n",
    "engine2 = create_engine(census_sql_data)\n",
    "# Create an inspector object from the engine\n",
    "inspector = inspect(engine2)\n",
    "# Use the inspector to list the table names\n",
    "table_names = inspector.get_table_names()\n",
    "print('Engine Table Names: \\n', table_names)\n",
    "\n",
    "connection = engine2.connect()\n",
    "metadata = MetaData()\n",
    "metadata.reflect(bind=engine)\n",
    "census = metadata.tables['census']\n",
    "print('\\nCensus:')\n",
    "census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use for remote connection\n",
    "# Create an engine to the census database\n",
    "engine = create_engine('mysql+pymysql://student:datacamp@courses.csrrinzqubik.us-east-1.rds.amazonaws.com:3306/census')\n",
    "inspector = inspect(engine)\n",
    "table_names = inspector.get_table_names()\n",
    "\n",
    "# Print the table names\n",
    "print('Engine Table Names: \\n', table_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Copy and run as code to use with remote engine\n",
    "connection = engine.connect()\n",
    "metadata = MetaData()\n",
    "census = Table('census', metadata, autoload=True, autoload_with=engine)\n",
    "print('\\nCensus:')\n",
    "census\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating a Difference between Two Columns\n",
    "\n",
    "Often, you'll need to perform math operations as part of a query, such as if you wanted to calculate the change in population from 2000 to 2008. For math operations on numbers, the operators in SQLAlchemy work the same way as they do in Python.\n",
    "\n",
    "You can use these operators to perform addition (<b>+</b>), subtraction (<b>-</b>), multiplication (<b>*</b>), division (<b>/</b>), and modulus (<b>%</b>) operations. Note: They behave differently when used with non-numeric column types.\n",
    "\n",
    "Let's now find the top 5 states by population growth between 2000 and 2008.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Define a select statement called **stmt** to return:\n",
    "    * i) The state column of the **census** table (**census.columns.state**).\n",
    "    * ii) The difference in population count between 2008 (**census.columns.pop2008**) and 2000 (**census.columns.pop2000**) labeled as **'pop_change'**.\n",
    "* Group the statement by **census.columns.state**.\n",
    "* Order the statement by population change (**'pop_change'**) in descending order. Do so by passing it **desc('pop_change')**.\n",
    "* Use the **.limit()** method on the statement to return only 5 records.\n",
    "* Execute the statement and **fetchall()** the records.\n",
    "* The print statement has already been written for you. Hit 'Submit Answer' to view the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build query to return state names by population difference from 2008 to 2000: stmt\n",
    "stmt = select(census.columns.state, (census.columns.pop2008 - census.columns.pop2000).label('pop_change'))\n",
    "\n",
    "# Append group by for the state: stmt\n",
    "stmt = stmt.group_by(census.columns.state)\n",
    "\n",
    "# Append order by for pop_change descendingly: stmt\n",
    "stmt = stmt.order_by(desc('pop_change'))\n",
    "\n",
    "# Return only 5 results: stmt\n",
    "stmt = stmt.limit(5)\n",
    "\n",
    "# Use connection to execute the statement and fetch all results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print the state and population change for each record\n",
    "for result in results:\n",
    "    print(f'{result.state}:{result.pop_change}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining the Overall Percentage of Females\n",
    "\n",
    "It's possible to combine functions and operators in a single select statement as well. These combinations can be exceptionally handy when we want to calculate percentages or averages, and we can also use the **case()** expression to operate on data that meets specific criteria while not affecting the query as a whole. The **case()** expression accepts a list of conditions to match and the column to return if the condition matches, followed by an **else_** if none of the conditions match. We can wrap this entire expression in any function or math operation we like.\n",
    "\n",
    "Often when performing integer division, we want to get a float back. While some databases will do this automatically, you can use the **cast()** function to convert an expression to a particular type.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Import **case**, **cast**, and **Float** from **sqlalchemy**.\n",
    "* Build an expression **female_pop2000** to calculate female population in 2000. To achieve this:\n",
    "    * Use **case()** inside **func.sum()**.\n",
    "    * The first argument of **case()** is a list containing a tuple of\n",
    "        * i) A boolean checking that **census.columns.sex** is equal to **'F'**.\n",
    "        * ii) The column **census.columns.pop2000**.\n",
    "    * The second argument is the **else_** condition, which should be set to 0.\n",
    "* Calculate the total population in 2000 and use **cast()** to convert it to **Float**.\n",
    "* Build a query to calculate the percentage of females in 2000. To do this, divide **female_pop2000** by **total_pop2000** and multiply by **100**.\n",
    "* Execute the query and print **percent_female**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import case, cast and Float from sqlalchemy - at top of notebook\n",
    "\n",
    "# Build an expression to calculate female population in 2000\n",
    "female_pop2000 = func.sum(case((census.columns.sex == 'F', census.columns.pop2000), else_=0))\n",
    "\n",
    "# Cast an expression to calculate total population in 2000 to Float\n",
    "total_pop2000 = cast(func.sum(census.columns.pop2000), Float)\n",
    "\n",
    "# Build a query to calculate the percentage of females in 2000: stmt\n",
    "stmt = select(female_pop2000 / total_pop2000 * 100)\n",
    "\n",
    "# Execute the query and store the scalar result: percent_female\n",
    "percent_female = connection.execute(stmt).scalar()\n",
    "percent_female"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relationships\n",
    "\n",
    "* Allow us to avoid duplicate data\n",
    "* Make it easy to change things in one place\n",
    "* Useful to break out information from a table we don’t need very often"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relationships\n",
    "\n",
    "![alt text](https://github.com/trenton3983/DataCamp/blob/master/Images/intro_to_databases_in_python/related.JPG?raw=true \"Related\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automatic Joins\n",
    "\n",
    "```python\n",
    "stmt = select(census.columns.pop2008, state_fact.columns.abbreviation)\n",
    "results = connection.execute(stmt).fetchall()\n",
    "print(results)\n",
    "\n",
    "Out:\n",
    "[(95012, u'IL'),\n",
    " (95012, u'NJ'),\n",
    " (95012, u'ND'),\n",
    " (95012, u'OR'),\n",
    " (95012, u'DC'),\n",
    " (95012, u'WI'),\n",
    " …\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join\n",
    "\n",
    "* Accepts a Table and an optional expression that explains how the two tables are related\n",
    "* The expression is not needed if the relationship is predefined and available via reflection\n",
    "* Comes immediately after the select() clause and prior to any where(), order_by or group_by() clauses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select_from\n",
    "\n",
    "* Used to replace the default, derived FROM clause with a join\n",
    "* Wraps the join() clause"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select_from Example\n",
    "\n",
    "```python\n",
    "stmt = select(func.sum(census.columns.pop2000))\n",
    "stmt = stmt.select_from(census.join(state_fact))\n",
    "stmt = stmt.where(state_fact.columns.circuit_court == '10')\n",
    "result = connection.execute(stmt).scalar()\n",
    "print(result)\n",
    "Out: 14945252\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joining Tables without Predefined Relationship\n",
    "\n",
    "* Join accepts a Table and an optional expression that explains how the two tables are related\n",
    "* Will only join on data that match between the two columns\n",
    "* Avoid joining on columns of different types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select_from Example\n",
    "\n",
    "```python\n",
    "stmt = select(func.sum(census.columns.pop2000))\n",
    "stmt = stmt.select_from(census.join(state_fact, census.columns.state == state_fact.columns.name))\n",
    "stmt = stmt.where(state_fact.columns.census_division_name == 'East South Central')\n",
    "result = connection.execute(stmt).scalar()\n",
    "print(result)\n",
    "\n",
    "Out: 16982311\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automatic Joins with an Established Relationship\n",
    "\n",
    "If you have two tables that already have an established relationship, you can automatically use that relationship by just adding the columns we want from each table to the select statement. Recall that Jason constructed the following query:\n",
    "\n",
    "```python\n",
    "stmt = select(census.columns.pop2008, state_fact.columns.abbreviation)\n",
    "```\n",
    "\n",
    "in order to join the **census** and **state_fact** tables and select the **pop2008** column from the first and the **abbreviation** column from the second. In this case, the **census** and **state_fact** tables had a pre-defined relationship: the **state** column of the former corresponded to the **name** column of the latter.\n",
    "\n",
    "In this exercise, you'll use the same predefined relationship to select the **pop2000** and **abbreviation** columns!\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Build a statement to join the **census** and **state_fact** tables and select the **pop2000** column from the first and the **abbreviation** column from the second.\n",
    "* Execute the statement to get the first result and save it as **result**.\n",
    "* Hit 'Submit Answer' to loop over the keys of the result object, and print the key and value for each!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_fact = Table('state_fact', metadata, autoload=True, autoload_with=engine2)\n",
    "state_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a statement to join census and state_fact tables: stmt\n",
    "stmt = select(census.columns.pop2000, state_fact.columns.abbreviation)\n",
    "\n",
    "# Execute the statement and get the first result: result\n",
    "result = connection.execute(stmt)\n",
    "\n",
    "# extract the rows\n",
    "row = result.fetchone()\n",
    "\n",
    "# Loop over the keys in the result object and print the key and value\n",
    "for key in result.keys():\n",
    "    print(key, getattr(row, key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joins\n",
    "\n",
    "If you aren't selecting columns from both tables or the two tables don't have a defined relationship, you can still use the **.join()** method on a table to join it with another table and get extra data related to our query. The **join()** takes the table object you want to join in as the first argument and a condition that indicates how the tables are related to the second argument. Finally, you use the **.select_from()** method on the select statement to wrap the join clause. For example, in the video, Jason executed the following code to join the **census** table to the **state_fact** table such that the **state** column of the **census** table corresponded to the **name** column of the **state_fact** table.\n",
    "\n",
    "```python\n",
    "stmt = stmt.select_from(\n",
    "    census.join(\n",
    "        state_fact, census.columns.state == \n",
    "        state_fact.columns.name)\n",
    "```\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Build a statement to select ALL the columns from the **census** and **state_fact** tables. To select ALL the columns from two tables **employees** and **sales**, for example, you would use **stmt = select(employees, sales)**.\n",
    "* Append a **select_from** to **stmt** to join the **census** table to the **state_fact** table by the **state** column in **census** and the **name** column in the **state_fact** table.\n",
    "* Execute the statement to get the first result and save it as **result**. This code is already written.\n",
    "* Hit 'Submit Answer' to loop over the keys of the result object, and print the key and value for each!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a statement to select the census and state_fact tables: stmt\n",
    "stmt = select(census, state_fact)\n",
    "\n",
    "# Add a select_from clause that wraps a join for the census and state_fact\n",
    "# tables where the census state column and state_fact name column match\n",
    "stmt = stmt.select_from(census.join(state_fact, census.columns.state == state_fact.columns.name))\n",
    "\n",
    "# Execute the statement and get the first result: result\n",
    "result = connection.execute(stmt)\n",
    "\n",
    "# extract the rows\n",
    "row = result.fetchone()\n",
    "\n",
    "# Loop over the keys in the result object and print the key and value\n",
    "for key in result.keys():\n",
    "    print(key, getattr(row, key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More Practice with Joins\n",
    "\n",
    "You can use the same select statement you built in the last exercise, however, let's add a twist and only return a few columns and use the other table in a **group_by()** clause.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Build a statement to select:\n",
    "    * The **state** column from the **census** table.\n",
    "    * The sum of the **pop2008** column from the **census** table.\n",
    "    * The **census_division_name** column from the **state_fact** table.\n",
    "* Append a **.select_from()** to **stmt** in order to join the **census** and **state_fact** tables by the **state** and **name** columns.\n",
    "* Group the statement by the **name** column of the **state_fact** table.\n",
    "* Execute the statement to get all the records and save it as **results**.\n",
    "* Hit 'Submit Answer' to loop over the **results** object and print each record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a statement to select the state, sum of 2008 population and census\n",
    "# division name: stmt\n",
    "stmt = select(census.columns.state,\n",
    "              func.sum(census.columns.pop2008),\n",
    "              state_fact.columns.census_division_name)\n",
    "\n",
    "# Append select_from to join the census and state_fact tables by the census state and state_fact name columns\n",
    "stmt = stmt.select_from(census.join(state_fact, census.columns.state == state_fact.columns.name))\n",
    "\n",
    "# Append a group by for the state_fact name column\n",
    "stmt = stmt.group_by(state_fact.columns.name)\n",
    "\n",
    "# Execute the statement and get the results: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Loop over the the results object and print each record.\n",
    "for record in results:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Hierarchical Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hierarchical Tables\n",
    "\n",
    "* Contain a relationship with themselves\n",
    "* Commonly found in:\n",
    "* Organizational\n",
    "* Geographic\n",
    "* Network\n",
    "* Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hierarchical Tables - Example\n",
    "\n",
    "![alt text](https://github.com/trenton3983/DataCamp/blob/master/Images/intro_to_databases_in_python/hierarchical.JPG?raw=true \"Hierarchical Table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hierarchical Tables - alias()\n",
    "\n",
    "* Requires a way to view the table via multiple names\n",
    "* Creates a unique reference that we can use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Querying Hierarchical Data\n",
    "\n",
    "```python\n",
    "managers = employees.alias()\n",
    "stmt = select(managers.columns.name.label('manager'), employees.columns.name.label('employee'))\n",
    "stmt = stmt.select_from(employees.join(managers, managers.columns.id == employees.columns.manager)\n",
    "stmt = stmt.order_by(managers.columns.name)\n",
    "print(connection.execute(stmt).fetchall())\n",
    "\n",
    "Out:    [(u'FILLMORE', u'GRANT'),\n",
    "         (u'FILLMORE', u'ADAMS'),\n",
    "         (u'HARDING', u'TAFT'), ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group_by and Func\n",
    "\n",
    "* It’s important to target group_by() at the right alias\n",
    "* Be careful with what you perform functions on\n",
    "* If you don’t find yourself using both the alias and the table name for a query, don’t create the alias at all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Querying Hierarchical Data\n",
    "\n",
    "```python\n",
    "managers = employees.alias()\n",
    "stmt = select(managers.columns.name, func.sum(employees.columns.sal))\n",
    "stmt = stmt.select_from(employees.join(managers, managers.columns.id == employees.columns.manager)\n",
    "stmt = stmt.group_by(managers.columns.name)\n",
    "print(connection.execute(stmt).fetchall())\n",
    "\n",
    "Out:    [(u'FILLMORE', Decimal('96000.00')),\n",
    "         (u'GARFIELD', Decimal('83500.00')),\n",
    "         (u'HARDING', Decimal('52000.00')),\n",
    "         (u'JACKSON', Decimal('197000.00'))]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Employees Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use with local file\n",
    "engine = create_engine(employees_sql_data)\n",
    "# Create an inspector object from the engine\n",
    "inspector = inspect(engine)\n",
    "# Use the inspector to list the table names\n",
    "table_names = inspector.get_table_names()\n",
    "print('Engine Table Names: \\n', table_names)\n",
    "\n",
    "connection = engine.connect()\n",
    "metadata = MetaData()\n",
    "\n",
    "# Reflect the database schema into MetaData. This loads table definitions from the database automatically.\n",
    "# The `bind=engine` argument tells MetaData which engine to use for connection.\n",
    "metadata.reflect(bind=engine)\n",
    "\n",
    "employees = metadata.tables['employees']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using alias to handle same table joined queries\n",
    "\n",
    "Often, you'll have tables that contain hierarchical data, such as employees and managers who are also employees. For this reason, you may wish to join a table to itself on different columns. The **.alias()** method, which creates a copy of a table, helps accomplish this task. Because it's the same table, you only need a where clause to specify the join condition.\n",
    "\n",
    "Here, you'll use the **.alias()** method to build a query to join the **employees** table against itself to determine to whom everyone reports.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Save an alias of the **employees** table as **managers**. To do so, apply the method **.alias()** to **employees**.\n",
    "* Build a query to select the employee **name** and their manager's **name**. The manager's **name** has already been selected for you. Use **label** to label the **name** column of **employees** as **'employee'**.\n",
    "* Append a where clause to **stmt** to match where the **id** column of the **managers** table corresponds to the **mgr** column of the **employees** table.\n",
    "* Order the statement by the **name** column of the **managers** table.\n",
    "* Execute the statement and store all the results. This code is already written. Hit 'Submit Answer' to print the names of the managers and all their employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an alias of the employees table: managers\n",
    "managers = employees.alias()\n",
    "\n",
    "# Build a query to select manager's and their employees names: stmt\n",
    "stmt = select(managers.columns.name.label('manager'), employees.columns.name.label('employee'))\n",
    "\n",
    "# Match managers id with employees mgr: stmt\n",
    "stmt = stmt.where(managers.columns.id == employees.columns.mgr)\n",
    "\n",
    "# Order the statement by the managers name: stmt\n",
    "stmt = stmt.order_by(managers.columns.name)\n",
    "\n",
    "# Execute statement: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print records\n",
    "for record in results:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leveraging Functions and Group_bys with Hierarchical Data\n",
    "\n",
    "It's also common to want to roll up data which is in a hierarchical table. Rolling up data requires making sure you're careful which alias you use to perform the group_bys and which table you use for the function.\n",
    "\n",
    "Here, your job is to get a count of employees for each manager.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Save an alias of the **employees** table as **managers**.\n",
    "* Build a query to select the **name** column of the **managers** table and the count of the number of their employees. The function **func.count()** has been imported and will be useful! Use it to count the **id** column of the **employees** table.\n",
    "* Using a **.where()** clause, filter the records where the **id** column of the **managers** table and **mgr** column of the **employees** table are equal.\n",
    "* Group the query by the **name** column of the **managers** table.\n",
    "* Execute the statement and store all the results. Print the names of the managers and their employees. This code has already been written so hit 'Submit Answer' and check out the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an alias of the employees table: managers\n",
    "managers = employees.alias()\n",
    "\n",
    "# Build a query to select managers and counts of their employees: stmt\n",
    "stmt = select(managers.columns.name, func.count(employees.columns.id))\n",
    "\n",
    "# Append a where clause that ensures the manager id and employee mgr are equal\n",
    "stmt = stmt.where(managers.columns.id == employees.columns.mgr)\n",
    "\n",
    "# Group by Managers Name\n",
    "stmt = stmt.group_by(managers.columns.name)\n",
    "\n",
    "# Execute statement: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# print manager\n",
    "for record in results:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Large Result Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with Large ResultSets\n",
    "\n",
    "* fetchmany() lets us specify how many rows we want to\n",
    "act upon\n",
    "* We can loop over fetchmany()\n",
    "* It returns an empty list when there are no more records\n",
    "* We have to close the ResultProxy afterwards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetching Many Rows\n",
    "\n",
    "```python\n",
    "while more_results:\n",
    "    partial_results = results_proxy.fetchmany(50)\n",
    "    if partial_results == []:\n",
    "        more_results = False\n",
    "    for row in partial_results:\n",
    "        state_count[row.state] += 1\n",
    "results_proxy.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Census Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import select - at top of Notebook\n",
    "\n",
    "engine = create_engine(census_sql_data)\n",
    "connection = engine.connect()\n",
    "metadata = MetaData()\n",
    "metadata.reflect(bind=engine)\n",
    "\n",
    "census = metadata.tables['census']\n",
    "\n",
    "# Build select statement for census table: stmt\n",
    "stmt = select(census)\n",
    "\n",
    "# Print the emitted statement to see the SQL emitted\n",
    "print(stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the statement and print the results\n",
    "results_proxy = connection.execute(stmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working on Blocks of Records\n",
    "\n",
    "Fantastic work so far! As Jason discussed in the video, sometimes you may have the need to work on a large ResultProxy, and you may not have the memory to load all the results at once. To work around that issue, you can get blocks of rows from the ResultProxy by using the **.fetchmany()** method inside a loop. With **.fetchmany()**, give it an argument of the number of records you want. When you reach an empty list, there are no more rows left to fetch, and you have processed all the results of the query. Then you need to use the **.close()** method to close out the connection to the database.\n",
    "\n",
    "You'll now have the chance to practice this on a large ResultProxy called **results_proxy** that has been pre-loaded for you to work with.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Use a **while** loop that checks if there are **more_results**.\n",
    "* Inside the loop, apply the method **.fetchmany()** to **results_proxy** to get **50** records at a time and store those records as **partial_results**.\n",
    "* After fetching the records, if **partial_results** is an empty list (that is, if it is equal to **[]**), set **more_results** to **False**.\n",
    "* Loop over the **partial_results** and, if **row.state** is a key in the **state_count** dictionary, increment **state_count[row.state]** by 1; otherwise set **state_count[row.state]** to 1.\n",
    "* After the while loop, close the ResultProxy **results_proxy** using **.close()**.\n",
    "* Hit 'Submit Answer' to print **state_count**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set more_results & state_count\n",
    "more_results = True\n",
    "state_count = dict()\n",
    "\n",
    "# Start a while loop checking for more results\n",
    "while more_results:\n",
    "    # Fetch the first 50 results from the ResultProxy: partial_results\n",
    "    partial_results = results_proxy.fetchmany(50)\n",
    "\n",
    "    # if empty list, set more_results to False\n",
    "    if partial_results == []:\n",
    "        more_results = False\n",
    "\n",
    "    # Loop over the fetched records and increment the count for the state\n",
    "    for row in partial_results:\n",
    "        if row.state in state_count:\n",
    "            state_count[row.state] += 1\n",
    "        else:\n",
    "            state_count[row.state] = 1\n",
    "\n",
    "# Close the ResultProxy, and thus the connection\n",
    "results_proxy.close()\n",
    "\n",
    "# Print the count by state\n",
    "pp(state_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Manipulating your own Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous chapters, you interacted with existing databases and queried them in various different ways. Now, you will learn how to build your own databases and keep them updated!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Databases and Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Databases\n",
    "\n",
    "* Varies by the database type\n",
    "* Databases like PostgreSQL and MySQL have command line tools to initialize the database\n",
    "* With **SQLite**, the **create_engine()** statement will create the database and file is they do not already exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a Table\n",
    "\n",
    "```python\n",
    "from sqlalchemy import (Table, Column, String, Integer, Decimal, Boolean)\n",
    "employees = Table('employees', metadata,\n",
    "                  Column('id', Integer()),\n",
    "                  Column('name', String(255)),\n",
    "                  Column('salary', Decimal()),\n",
    "                  Column('active', Boolean()))\n",
    "metadata.create_all(engine)\n",
    "engine.table_names()\n",
    "[u'employees']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Tables\n",
    "\n",
    "* Still uses the Table object like we did for reflection\n",
    "* Replaces the autoload keyword arguments with Column objects\n",
    "* Creates the tables in the actual database by using the create_all() method on the MetaData instance\n",
    "* You need to use other tools to handle database table updates, such as Alembic or raw SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Tables - Additional Column Options\n",
    "\n",
    "* **unique** forces all values for the data in a column to be unique\n",
    "* **nullable** determines if a column can be empty in a row\n",
    "* **default** sets a default value if one isn’t supplied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a Table with Additional Options\n",
    "\n",
    "```python\n",
    "employees = Table('employees', metadata,\n",
    "                  Column('id', Integer()),\n",
    "                  Column('name', String(255), unique=True, nullable=False),\n",
    "                  Column('salary', Float(), default=100.00),\n",
    "                  Column('active', Boolean(), default=True))\n",
    "employees.constraints\n",
    "\n",
    "Out:    {CheckConstraint(Column('name', String(length=255), table=<employees>, nullable=False),\n",
    "                         Column('salary', Float(), table=<employees>, default=ColumnDefault(100.0)),\n",
    "                         Column('active', Boolean(), table=<employees>, default=ColumnDefault(True)) ...\n",
    "         UniqueConstraint(Column('name', String(length=255), table=<employees>, nullable=False))}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Tables with SQLAlchemy\n",
    "\n",
    "Previously, you used the **Table** object to reflect a table from an existing database, but what if you wanted to create a new table? You'd still use the **Table** object; however, you'd need to replace the **autoload** and **autoload_with** parameters with Column objects.\n",
    "\n",
    "The **Column** object takes a name, a SQLAlchemy type with an optional format, and optional keyword arguments for different constraints.\n",
    "\n",
    "When defining the table, recall how in the video Jason passed in **255** as the maximum length of a String by using **Column('name', String(255))**. Checking out the slides from the video may help: you can download them by clicking on 'Slides' next to the IPython Shell.\n",
    "\n",
    "After defining the table, you can create the table in the database by using the **.create_all()** method on metadata and supplying the engine as the only parameter. Go for it!\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Import Table, Column, String, Integer, Float, Boolean from sqlalchemy.\n",
    "* Build a new table called data with columns 'name' (String(255)), 'count' (Integer()), 'amount'(Float()), and 'valid' (Boolean()) columns. The second argument of Table() needs to be metadata, which has already been initialized.\n",
    "* Create the table in the database by passing **engine** to **metadata.create_all()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = MetaData()\n",
    "\n",
    "# Define a new table with a name, count, amount, and valid column: data\n",
    "test_data = Table('test_data', metadata,\n",
    "                  Column('name', String(255)),\n",
    "                  Column('count', Integer()),\n",
    "                  Column('amount', Float()),\n",
    "                  Column('valid', Boolean()))\n",
    "\n",
    "engine = create_engine('sqlite:///data/intro_to_databases_in_python/test_data.sqlite')\n",
    "connection = engine.connect()\n",
    "\n",
    "# Use the metadata to create the table\n",
    "metadata.create_all(engine)\n",
    "\n",
    "# Print table details\n",
    "print(repr(test_data))\n",
    "\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contraints and Data Defaults\n",
    "\n",
    "You're now going to practice creating a table with some constraints! Often, you'll need to make sure that a column is unique, nullable, a positive value, or related to a column in another table. This is where constraints come in.\n",
    "\n",
    "As Jason showed you in the video, in addition to constraints, you can also set a default value for the column if no data is passed to it via the default keyword on the column.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Table, Column, String, Integer, Float, Boolean are already imported from sqlalchemy.\n",
    "* Build a new table called data with a unique name (String), count (Integer) defaulted to 1, amount (Float), and valid (Boolean) defaulted to False.\n",
    "* Hit 'Submit Answer' to create the table in the database and to print the table details for data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = MetaData()\n",
    "\n",
    "# Define a new table with a name, count, amount, and valid column: data\n",
    "test_data = Table('test_data', metadata,\n",
    "                  Column('name', String(255), unique=True),\n",
    "                  Column('count', Integer(), default=1),\n",
    "                  Column('amount', Float()),\n",
    "                  Column('valid', Boolean(), default=False),\n",
    "                  extend_existing=True)\n",
    "\n",
    "engine = create_engine('sqlite:///:memory:')\n",
    "connection = engine.connect()\n",
    "\n",
    "# Use the metadata to create the table\n",
    "metadata.create_all(engine)\n",
    "\n",
    "# Print the table details\n",
    "print(repr(metadata.tables['test_data']))\n",
    "\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting Data into a Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Data to a Table\n",
    "\n",
    "* Done with the insert() statement\n",
    "* Insert() takes the table we are loading data into as the argument\n",
    "* We add all the values we want to insert in with the values clause as column=value pairs\n",
    "* Doesn’t return any rows, so no need for a fetch method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserting One Row\n",
    "\n",
    "```python\n",
    "from sqlalchemy import insert\n",
    "stmt = insert(employees).values(id=1, name='Jason', salary=1.00, active=True)\n",
    "result_proxy = connection.execute(stmt)\n",
    "print(result_proxy.rowcount)\n",
    "Out: 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserting Multiple Rows\n",
    "\n",
    "* Build an insert statement without any values\n",
    "* Build a list of dictionaries that represent all the values clauses for the rows you want to insert\n",
    "* Pass both the stmt and the values list to the execute method on connection\n",
    "\n",
    "```python\n",
    "stmt = insert(employees)\n",
    "values_list = [{'id': 2, 'name': 'Rebecca', 'salary': 2.00, 'active': True},\n",
    "               {'id': 3, 'name': 'Bob', 'salary': 0.00, 'active': False}]\n",
    "result_proxy = connection.execute(stmt, values_list)\n",
    "print(result_proxy.rowcount)\n",
    "Out: 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserting a single row with an insert() statement\n",
    "\n",
    "There are several ways to perform an insert with SQLAlchemy; however, we are going to focus on the one that follows the same pattern as the select statement.\n",
    "\n",
    "It uses an insert statement where you specify the table as an argument, and supply the data you wish to insert into the value via the .values() method as keyword arguments.\n",
    "\n",
    "Here, the name of the table is data.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Import insert and select from the sqlalchemy module.\n",
    "* Build an insert statement for the data table to set name to 'Anna', count to 1, amount to 1000.00, and valid to True. Save the statement as stmt.\n",
    "* Execute stmt with the connection and store the results.\n",
    "* Print the rowcount attribute of results to see how many records were inserted.\n",
    "* Build a select statement to query for the record with the name of 'Anna'.\n",
    "* Hit 'Submit Answer' to print the results of executing the select statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use with local file\n",
    "engine = create_engine('sqlite:///data/intro_to_databases_in_python/test_data.sqlite')\n",
    "\n",
    "inspector = inspect(engine)\n",
    "table_names = inspector.get_table_names()\n",
    "\n",
    "print('Engine Table Names: \\n', table_names)\n",
    "\n",
    "connection = engine.connect()\n",
    "metadata = MetaData()\n",
    "metadata.reflect(bind=engine)\n",
    "test_data = metadata.tables['test_data']\n",
    "\n",
    "print('\\nTest Data:')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an insert statement to insert a record into the data table: stmt\n",
    "stmt = insert(test_data).values(name='Anna', count=1, amount=1000.00, valid=True)\n",
    "\n",
    "# Execute the statement via the connection: results\n",
    "results = connection.execute(stmt)\n",
    "\n",
    "# Print result rowcount\n",
    "print(results.rowcount)\n",
    "\n",
    "# Build a select statement to validate the insert\n",
    "stmt = select(test_data).where(test_data.columns.name == 'Anna')\n",
    "\n",
    "# Print the result of executing the query.\n",
    "print(connection.execute(stmt).first())\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserting Multiple Records at Once\n",
    "\n",
    "It's time to practice inserting multiple records at once!\n",
    "\n",
    "As Jason showed you in the video, you'll want to first build a list of dictionaries that represents the data you want to insert. Then, in the **.execute()** method, you can pair this list of dictionaries with an **insert** statement, which will insert all the records in your list of dictionaries.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Build a list of dictionaries called **values_list** with two dictionaries. In the first dictionary set **name** to **'Anna'**, **count** to <b>1</b>, **amount** to **1000.00**, and **valid** to **True**. In the second dictionary of the list, set **name** to **'Taylor'**, **count** to <b>1</b>, **amount** to **750.00**, and **valid** to **False**.\n",
    "* Build an **insert** statement for the **data** table for a multiple insert, save it as **stmt**.\n",
    "* Execute **stmt** with the **values_list** via **connection** and store the **results**. Make sure **values_list** is the second argument to **.execute()**.\n",
    "* Print the **rowcount** of the **results**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///data/intro_to_databases_in_python/test_data.sqlite')\n",
    "inspector = inspect(engine)\n",
    "table_names = inspector.get_table_names()\n",
    "\n",
    "print('Engine Table Names: \\n', table_names)\n",
    "\n",
    "connection = engine.connect()\n",
    "metadata = MetaData()\n",
    "metadata.reflect(bind=engine)\n",
    "test_data = metadata.tables['test_data']\n",
    "\n",
    "print('\\nTest Data:')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a list of dictionaries: values_list\n",
    "values_list = [{'name': 'Alexandria', 'count': 1, 'amount': 1000.00, 'valid': True},\n",
    "               {'name': 'Taylor', 'count': 1, 'amount': 750.00, 'valid': False}]\n",
    "\n",
    "# Build an insert statement for the data table: stmt\n",
    "stmt = insert(test_data)\n",
    "\n",
    "# Execute stmt with the values_list: results\n",
    "results = connection.execute(stmt, values_list)\n",
    "\n",
    "# Print rowcount\n",
    "print(results.rowcount)\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading a CSV into a Table\n",
    "\n",
    "You've done a great job so far at inserting data into tables! You're now going to learn how to load the contents of a CSV file into a table.\n",
    "\n",
    "We have used the **csv** module to set up a **csv_reader**, which is just a reader object that can iterate over the lines in a given CSV file - in this case, a census CSV file. Using the **enumerate()** function, you can loop over the **csv_reader** to handle the results one at a time. Here, for example, the first line it would return is:\n",
    "\n",
    "```python\n",
    "0 ['Illinois', 'M', '0', '89600', '95012']\n",
    "```\n",
    "\n",
    "<b>0</b> is the **idx** - or line number - while **['Illinois', 'M', '0', '89600', '95012']** is the **row**, corresponding to the column names **'state'** , **'sex'**, **'age'**, **'pop2000 '**and **'pop2008'**. **'Illinois'** can be accessed with **row[0]**, **'M'** with **row[1]**, and so on. You can create a dictionary containing this information where the keys are the column names and the values are the entries in each line. Then, by appending this dictionary to a list, you can combine it with an insert statement to load it all into a table!\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Create a statement for bulk insert into the **census** table. To do this, just use **insert()** and **census**.\n",
    "* Create an empty list called **values_list** and a variable called **total_rowcount** that is set to **0**.\n",
    "* Within the **for** loop:\n",
    "    * Complete the **data** dictionary by filling in the values for each of the keys. The values are contained in **row**. **row[0]** represents the value for **'state'**, **row[1]** represents the value for **'sex'**, and so on.\n",
    "    * Append **data** to **values_list**.\n",
    "    * If **51** cleanly divides into the current **idx**:\n",
    "        * Execute **stmt** with the **values_list** and save it as **results**.\n",
    "* Hit 'Submit Answer' to print **total_rowcount** when done with all the records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_reader = list()\n",
    "\n",
    "with open(census_csv_data, newline='\\n') as csvfile:\n",
    "    file_reader = csv.reader(csvfile)\n",
    "    for row in file_reader:\n",
    "        csv_reader.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(census_sql_data)\n",
    "inspector = inspect(engine)\n",
    "table_names = inspector.get_table_names()\n",
    "print('Engine Table Names: \\n', table_names)\n",
    "\n",
    "connection = engine.connect()\n",
    "metadata = MetaData()\n",
    "metadata.reflect(bind=engine)\n",
    "census = metadata.tables['census']\n",
    "print('\\nTest Data:')\n",
    "census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a insert statement for census: stmt\n",
    "stmt = insert(census)\n",
    "\n",
    "# Create an empty list and zeroed row count: values_list, total_rowcount\n",
    "values_list = []\n",
    "total_rowcount = 0\n",
    "\n",
    "# Enumerate the rows of csv_reader\n",
    "for idx, row in enumerate(csv_reader):\n",
    "    #create data and append to values_list\n",
    "    data = {'state': row[0], 'sex': row[1], 'age': row[2], 'pop2000': row[3], 'pop2008': row[4]}\n",
    "    values_list.append(data)\n",
    "\n",
    "    # Check to see if divisible by 51\n",
    "    if idx % 51 == 0:\n",
    "        results = connection.execute(stmt, values_list)\n",
    "        total_rowcount += results.rowcount\n",
    "        values_list = []\n",
    "\n",
    "# Print total rowcount\n",
    "print(total_rowcount)\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Data in a Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating Data in a Table\n",
    "\n",
    "* Done with the update statement\n",
    "* Similar to the insert statement but includes a where clause to determine what record will be updated\n",
    "* We add all the values we want to update with the values clause as column=value pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating One Row\n",
    "\n",
    "```python\n",
    "from sqlalchemy import update\n",
    "stmt = update(employees)\n",
    "stmt = stmt.where(employees.columns.id == 3)\n",
    "stmt = stmt.values(active=True)\n",
    "result_proxy = connection.execute(stmt)\n",
    "print(result_proxy.rowcount)\n",
    "Out: 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating Multiple Rows\n",
    "\n",
    "* Build a where clause that will select all the records you want to update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserting Multiple Rows\n",
    "\n",
    "```python\n",
    "stmt = update(employees)\n",
    "stmt = stmt.where(employees.columns.active == True)\n",
    "stmt = stmt.values(active=False, salary=0.00)\n",
    "result_proxy = connection.execute(stmt)\n",
    "print(result_proxy.rowcount)\n",
    "Out: 3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlated Updates\n",
    "\n",
    "```python\n",
    "new_salary = select(employees.columns.salary)\n",
    "new_salary = new_salary.order_by(desc(employees.columns.salary))\n",
    "new_salary = new_salary.limit(1)\n",
    "stmt = update(employees)\n",
    "stmt = stmt.values(salary=new_salary)\n",
    "result_proxy = connection.execute(stmt)\n",
    "print(result_proxy.rowcount)\n",
    "\n",
    "Out: 3\n",
    "```\n",
    "\n",
    "* Uses a select() statement to find the value for the column we are updating\n",
    "* Commonly used to update records to a maximum value or change a string to match an abbreviation from another table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples - Original\n",
    "\n",
    "Following is the original content for the class, which has not been updated to run `sqlalchemy 2.0.29`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating individual records\n",
    "\n",
    "The **update** statement is very similar to an **insert** statement, except that it also typically uses a **where** clause to help us determine what data to update. You'll be using the FIPS state code using here, which is appropriated by the U.S. government to identify U.S. states and certain other associated areas. Recall that you can update all wages in the **employees** table as follows:\n",
    "\n",
    "```python\n",
    "stmt = update(employees).values(wage=100.00)\n",
    "```\n",
    "\n",
    "For your convenience, the names of the tables and columns of interest in this exercise are: **state_fact** (Table), **name** (Column), and **fips_state** (Column).\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Build a statement to select all columns from the **state_fact** table where the **name** column is New York. Call it **select_stmt**.\n",
    "* Print the results of executing the **select_stmt** and fetching all records.\n",
    "* Build an **update** statement to change the **fips_state** column code to **36**, save it as **stmt**.\n",
    "* Use a **where** clause to filter for states with the **name** of **'New York'** in the **state_fact** table.\n",
    "* Execute **stmt** via the **connection** and save the output as **results**.\n",
    "* Hit 'Submit Answer' to print the **rowcount** of the **results** and the results of executing **select_stmt**. This will verify the fips_state code is now 36."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "engine = create_engine(census_sql_data)\n",
    "print('Engine Table Names: \\n', engine.table_names())\n",
    "\n",
    "connection = engine.connect()\n",
    "metadata = MetaData()\n",
    "state_fact = Table('state_fact', metadata, autoload=True, autoload_with=engine)\n",
    "print('\\nTest Data:')\n",
    "state_fact\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Build a select statement: select_stmt\n",
    "select_stmt = select([state_fact]).where(state_fact.columns.name == 'New York')\n",
    "# Print the results of executing the select_stmt\n",
    "print(connection.execute(select_stmt).fetchall())\n",
    "# Build a statement to update the fips_state to 36: stmt\n",
    "stmt = update(state_fact).values(fips_state = 36)\n",
    "# Append a where clause to limit it to records for New York state\n",
    "stmt = stmt.where(state_fact.columns.name == 'New York')\n",
    "# Execute the statement: results\n",
    "results = connection.execute(stmt)\n",
    "# Print rowcount\n",
    "print(results.rowcount)\n",
    "# Execute the select_stmt again to view the changes\n",
    "print(connection.execute(select_stmt).fetchall())\n",
    "connection.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating Multiple Records\n",
    "\n",
    "As Jason discussed in the video, by using a **where** clause that selects more records, you can update multiple records at once. It's time now to practice this!\n",
    "\n",
    "For your convenience, the names of the tables and columns of interest in this exercise are: **state_fact** (Table), **notes** (Column), and **census_region_name** (Column).\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Build an **update** statement to update the **notes** column in the **state_fact** table to **'The Wild West'**. Save it as **stmt**.\n",
    "* Use a **where** clause to filter for records that have **'West'** in the **census_region_name** column of the **state_fact** table.\n",
    "* Execute **stmt** via the **connection** and save the output as **results**.\n",
    "* Hit 'Submit Answer' to print **rowcount** of the **results**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "engine = create_engine(census_sql_data)\n",
    "print('Engine Table Names: \\n', engine.table_names())\n",
    "\n",
    "connection = engine.connect()\n",
    "metadata = MetaData()\n",
    "state_fact = Table('state_fact', metadata, autoload=True, autoload_with=engine)\n",
    "print('\\nTest Data:')\n",
    "state_fact\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Build a statement to update the notes to 'The Wild West': stmt\n",
    "stmt = update(state_fact).values(notes = 'The Wild West')\n",
    "# Append a where clause to match the West census region records\n",
    "stmt = stmt.where(state_fact.columns.census_region_name == 'West')\n",
    "# Execute the statement: results\n",
    "results = connection.execute(stmt)\n",
    "# Print rowcount\n",
    "print(results.rowcount)\n",
    "connection.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlated Updates\n",
    "\n",
    "You can also update records with data from a select statement. This is called a correlated update. It works by defining a select statement that returns the value you want to update the record with and assigning that as the value in an update statement.\n",
    "\n",
    "You'll be using a flat_census in this exercise as the target of your correlated update. The flat_census table is a summarized copy of your census table.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Build a statement to select the name column from state_fact. Save the statement as fips_stmt.\n",
    "* Append a where clause to fips_stmt that matches fips_state from the state_fact table with fips_code in the flat_census table.\n",
    "* Build an update statement to set the state_name in flat_census to fips_stmt. Save the statement as update_stmt.\n",
    "* Hit 'Submit Answer' to execute update_stmt, store the results and print the rowcount of results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create flat_census table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "metadata = MetaData()\n",
    "# Define a new table with a name, count, amount, and valid column: data\n",
    "flat_census = Table('flat_census', metadata,\n",
    "                  Column('state_name', String(255)),\n",
    "                  Column('fips_code', String(255)),\n",
    "                  extend_existing=True)\n",
    "\n",
    "engine = create_engine(census_sql_data)\n",
    "connection = engine.connect()\n",
    "# Use the metadata to create the table\n",
    "metadata.create_all(engine)\n",
    "# Print the table details\n",
    "print(repr(metadata.tables['flat_census']))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Copy fips_state values from the state_fact table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "state_fact = Table('state_fact', metadata, autoload=True, autoload_with=engine)\n",
    "results = connection.execute(select([state_fact.columns.fips_state])).fetchall()\n",
    "\n",
    "print(results[:5])\n",
    "print(len(results))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a df with results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "df = pd.DataFrame(results, columns=['fips_code'])\n",
    "df.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write the df to fips_code in the flat_census table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "df.to_sql('flat_census', con=engine, index=False, if_exists='append')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Complete the example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Build a statement to select name from state_fact: stmt\n",
    "fips_stmt = select([state_fact.columns.name])\n",
    "# Append a where clause to Match the fips_state to flat_census fips_code\n",
    "fips_stmt = fips_stmt.where(state_fact.columns.fips_state == flat_census.columns.fips_code)\n",
    "# Build an update statement to set the name to fips_stmt: update_stmt\n",
    "update_stmt = update(flat_census).values(state_name = fips_stmt)\n",
    "# Execute update_stmt: results\n",
    "results = connection.execute(update_stmt)\n",
    "# Print rowcount\n",
    "print(results.rowcount)\n",
    "connection.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples - Updated\n",
    "\n",
    "The previous examples have been updated to function with `sqlalchemy 2.0.29`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Notes\n",
    "\n",
    "**Database and Table Setup:**\n",
    "- Create a database connection using `create_engine` with specific connection arguments to handle multithreading and timeout settings.\n",
    "- Define a `flat_census` table within a metadata object, specifying columns for state names and FIPS codes. Design this table to either be created or have its existing schema extended.\n",
    "\n",
    "**Reflection and Table Access:**\n",
    "- Use `metadata.reflect()` to load existing table definitions from the database into the SQLAlchemy context. This enables interaction with previously defined tables such as `state_fact`.\n",
    "\n",
    "**Basic Data Operations:**\n",
    "- Perform a basic data retrieval operation using a `select` statement filtered by the state name ('New York'). Execute the query within a session and fetch results.\n",
    "- Update data by changing the FIPS state code for New York to 36. This operation illustrates the transactional nature of the session, which requires a commit to save changes.\n",
    "\n",
    "**Advanced Data Operations - Correlated Update:**\n",
    "- Construct a correlated subquery to update the `flat_census` table. Explain how the subquery fetches the state name from `state_fact` where FIPS codes match between `state_fact` and `flat_census`.\n",
    "- Execute the update operation to align the `state_name` in `flat_census` based on the results of the subquery. Emphasize the importance of committing the session to apply changes.\n",
    "\n",
    "**Commitment and Closure:**\n",
    "- Commit the session after executing database operations to ensure all changes are saved. Then close the session to release database resources.\n",
    "\n",
    "**Summary:**\n",
    "- The instructions cover creating and configuring a database engine, defining and reflecting tables, and performing both simple and complex database operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Synopsis\n",
    "\n",
    "- **Set up the database connection** using `create_engine` with specific parameters for multithreading and timeout.\n",
    "- **Define and create the `flat_census` table** if it does not already exist, with columns for `state_name` and `fips_code`, and ensure it can extend an existing schema.\n",
    "- **Reflect all existing tables** from the database to ensure they are loaded into SQLAlchemy's metadata.\n",
    "- **Access the `state_fact` table** from the reflected metadata.\n",
    "- **Open a session** and perform several operations within it:\n",
    "  - **Retrieve and print records** for New York from the `state_fact` table.\n",
    "  - **Update the FIPS state code** for New York to 36, commit the session, and print the number of rows updated.\n",
    "  - **Print updated records** for New York to confirm the update.\n",
    "  - **Update the `notes` field** for records where the census region is 'West' to 'The Wild West', commit the session, and print the number of rows updated.\n",
    "  - **Retrieve and display the first five FIPS states** from the `state_fact` table.\n",
    "  - **Export FIPS states** to the `flat_census` table using a DataFrame and the `to_sql` method.\n",
    "  - **Create and execute a correlated subquery** to update the `state_name` in the `flat_census` table based on matching FIPS codes between `state_fact` and `flat_census`.\n",
    "  - **Commit the session** after updates and print the number of rows affected by the correlated update.\n",
    "- **Close the session** to release resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection string and engine setup\n",
    "engine = create_engine(census_sql_data, connect_args={'check_same_thread': False, 'timeout': 15})\n",
    "metadata = MetaData()\n",
    "\n",
    "# Define the 'flat_census' table if it doesn't exist\n",
    "flat_census = Table('flat_census', metadata,\n",
    "                    Column('state_name', String(255)),\n",
    "                    Column('fips_code', String(255)),\n",
    "                    extend_existing=True)\n",
    "\n",
    "# Create or extend the table in the database\n",
    "metadata.create_all(engine)\n",
    "\n",
    "# Reflect the existing tables to ensure all are loaded\n",
    "metadata.reflect(bind=engine)\n",
    "\n",
    "# Accessing the tables\n",
    "state_fact = metadata.tables['state_fact']\n",
    "\n",
    "with Session(engine) as session:\n",
    "    # Operations on state_fact\n",
    "    select_stmt = select(state_fact).where(state_fact.c.name == 'New York')\n",
    "    new_york_records = session.execute(select_stmt).fetchall()\n",
    "    print('New York Records:', new_york_records)\n",
    "\n",
    "    update_stmt = update(state_fact).where(state_fact.c.name == 'New York').values(fips_state=36)\n",
    "    result = session.execute(update_stmt)\n",
    "    session.commit()\n",
    "    print('Rows updated:', result.rowcount)\n",
    "\n",
    "    updated_records = session.execute(select_stmt).fetchall()\n",
    "    print('Updated New York Records:', updated_records)\n",
    "\n",
    "    update_stmt_west = update(state_fact).where(state_fact.c.census_region_name == 'West').values(notes='The Wild West')\n",
    "    result_west = session.execute(update_stmt_west)\n",
    "    session.commit()\n",
    "    print('Rows updated in West:', result_west.rowcount)\n",
    "\n",
    "    fips_results = session.execute(select(state_fact.c.fips_state)).fetchall()\n",
    "    print('FIPS States:', fips_results[:5])\n",
    "\n",
    "    # Exporting to flat_census using DataFrame\n",
    "    df = pd.DataFrame(fips_results, columns=['fips_code'])\n",
    "    display(df.head())\n",
    "    df.to_sql('flat_census', con=engine, index=False, if_exists='append', method='multi')\n",
    "\n",
    "    # Build a statement to select name from state_fact where fips_state matches flat_census fips_code\n",
    "    fips_stmt = select(state_fact.c.name).\\\n",
    "        where(state_fact.c.fips_state == flat_census.c.fips_code).\\\n",
    "        scalar_subquery()\n",
    "    \n",
    "    # Build an update statement to set the state_name in flat_census to the name selected from state_fact\n",
    "    update_stmt = update(flat_census).values(state_name=fips_stmt)\n",
    "    \n",
    "    # Execute update_stmt using the session\n",
    "    result = session.execute(update_stmt)\n",
    "    session.commit()\n",
    "    \n",
    "    # Print rowcount\n",
    "    print(result.rowcount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Data From a Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleting Data from a Table\n",
    "\n",
    "* Done with the delete() statement\n",
    "* delete() takes the table we are loading data into as the argument\n",
    "* A where() clause is used to choose which rows to delete\n",
    "* Hard to undo so BE CAREFUL!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleting all Data from a Table\n",
    "\n",
    "```python\n",
    "from sqlalchemy import delete\n",
    "stmt = select(func.count(extra_employees.columns.id))\n",
    "connection.execute(stmt).scalar()\n",
    "Out: 3\n",
    "\n",
    "delete_stmt = delete(extra_employees)\n",
    "result_proxy = connection.execute(delete_stmt)\n",
    "result_proxy.rowcount\n",
    "Out: 3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleting Specific Rows\n",
    "\n",
    "* Build a where clause that will select all the records you want to delete\n",
    "\n",
    "```python\n",
    "stmt = delete(employees).where(employees.columns.id == 3)\n",
    "result_proxy = connection.execute(stmt)\n",
    "result_proxy.rowcount\n",
    "Out: 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping a Table Completely\n",
    "\n",
    "* Uses the drop method on the table\n",
    "* Accepts the engine as an argument so it knows where to remove the table from\n",
    "* Won’t remove it from metadata until the python process is restarted\n",
    "\n",
    "```python\n",
    "extra_employees.drop(engine)\n",
    "print(extra_employees.exists(engine))\n",
    "Out: False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping all the Tables\n",
    "\n",
    "* Uses the drop_all() method on MetaData\n",
    "\n",
    "```python\n",
    "metadata.drop_all(engine)\n",
    "engine.table_names()\n",
    "Out: []\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleting all the records from a table\n",
    "\n",
    "Often, you'll need to empty a table of all of its records so you can reload the data. You can do this with a **delete** statement with just the table as an argument. For example, in the video, Jason deleted the table **extra_employees** by executing as follows:\n",
    "```python\n",
    "delete_stmt = delete(extra_employees)\n",
    "result_proxy = connection.execute(delete_stmt)\n",
    "```\n",
    "Do be careful, though, as deleting cannot be undone!\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Import **delete** and **select** from sqlalchemy.\n",
    "* Build a **delete** statement to remove all the data from the **census** table. Save it as **stmt**.\n",
    "* Execute **stmt** via the **connection** and save the **results**.\n",
    "* Hit 'Submit Answer' to **select** all remaining rows from the **census** table and print the result to confirm that the table is now empty!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Connect to the database and create a new table (census2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(census_sql_data)\n",
    "inspector = inspect(engine)\n",
    "table_names = inspector.get_table_names()\n",
    "print('Engine Table Names: \\n', table_names)\n",
    "\n",
    "connection = engine.connect()\n",
    "metadata = MetaData()\n",
    "metadata.reflect(bind=engine)\n",
    "census = metadata.tables['census']\n",
    "\n",
    "results = connection.execute(select(census)).fetchall()\n",
    "df = pd.DataFrame(results)\n",
    "df.columns = ['state', 'sex', 'age', 'pop2000', 'pop2008']\n",
    "_dtypes = {'state': String(30), 'sex': String(1), 'age': Integer(), 'pop2000': Integer(), 'pop2008': Integer()}\n",
    "\n",
    "df.to_sql('census2', con=engine, index=False, if_exists='replace', dtype=_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Complete the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census2 = Table('census2', metadata, autoload_with=engine)\n",
    "\n",
    "# Build a statement to empty the census table: stmt\n",
    "stmt = delete(census2)\n",
    "\n",
    "# Execute the statement: results\n",
    "results = connection.execute(stmt)\n",
    "\n",
    "# Print affected rowcount\n",
    "print(results.rowcount)\n",
    "\n",
    "# Build a statement to select all records from the census table\n",
    "stmt = select(census2)\n",
    "\n",
    "# Print the results of executing the statement to verify there are no rows\n",
    "print(connection.execute(stmt).fetchall())\n",
    "\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleting specific records\n",
    "\n",
    "By using a **where()** clause, you can target the **delete** statement to remove only certain records. For example, Jason deleted all rows from the **employees** table that had **id** 3 with the following delete statement:\n",
    "```python\n",
    "delete(employees).where(employees.columns.id == 3) \n",
    "```\n",
    "Here you'll delete ALL rows which have **'M'** in the **sex** column and **36** in the **age** column. We have included code at the start which computes the total number of these rows. It is important to make sure that this is the number of rows that you actually delete.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Build a **delete** statement to remove data from the **census** table. Save it as **stmt_del**.\n",
    "* Append a **where** clause to **stmt_del** that contains an **and_** to filter for rows which have **'M'** in the **sex** column <b>AND</b> **36** in the **age** column.\n",
    "* Execute the delete statement.\n",
    "* Hit 'Submit Answer' to print the **rowcount** of the **results**, as well as **to_delete**, which returns the number of rows that should be deleted. These should match and this is an important sanity check!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Connect to the database and create a new table (census2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(census_sql_data)\n",
    "inspector = inspect(engine)\n",
    "table_names = inspector.get_table_names()\n",
    "print('Engine Table Names: \\n', table_names)\n",
    "\n",
    "connection = engine.connect()\n",
    "metadata = MetaData()\n",
    "metadata.reflect(bind=engine)\n",
    "census = metadata.tables['census']\n",
    "\n",
    "results = connection.execute(select(census)).fetchall()\n",
    "df = pd.DataFrame(results)\n",
    "df.columns = ['state', 'sex', 'age', 'pop2000', 'pop2008']\n",
    "_dtypes = {'state': String(30), 'sex': String(1), 'age': Integer(), 'pop2000': Integer(), 'pop2008': Integer()}\n",
    "\n",
    "df.to_sql('census2', con=engine, index=False, if_exists='replace', dtype=_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Complete the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census2 = Table('census2', metadata, autoload_with=engine)\n",
    "\n",
    "# Build a statement to count records using the sex column for Men ('M') age 36: stmt\n",
    "stmt = select(func.count(census2.columns.sex)).where(and_(census2.columns.sex == 'M', census2.columns.age == 36))\n",
    "\n",
    "# Execute the select statement and use the scalar() fetch method to save the record count\n",
    "to_delete = connection.execute(stmt).scalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a statement to delete records from the census table: stmt_del\n",
    "stmt_del = delete(census2)\n",
    "\n",
    "# Append a where clause to target Men ('M') age 36\n",
    "stmt_del = stmt_del.where(and_(census2.columns.sex == 'M', census2.columns.age == 36))\n",
    "\n",
    "# Execute the statement: results\n",
    "results = connection.execute(stmt_del)\n",
    "\n",
    "# Print affected rowcount and to_delete record count, make sure they match\n",
    "print(results.rowcount, to_delete)\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleting a Table Completely\n",
    "\n",
    "You're now going to practice dropping individual tables from a database with the **.drop()** method, as well as all tables in a database with the **.drop_all()** method!\n",
    "\n",
    "As Spider-Man's Uncle Ben (as well as Jason, in the video!) said: With great power, comes great responsibility. Do be careful when deleting tables, as it's not simple or fast to restore large databases! Remember, you can check to see if a table exists with the **.exists()** method.\n",
    "\n",
    "This is the final exercise in this chapter: After this, you'll be ready to apply everything you've learned to a case study in the final chapter of this course!\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Drop the **state_fact** table by applying the method **.drop()** to it and passing it the argument **engine** (in fact, **engine** will be the sole argument for every function/method in this exercise!)\n",
    "* Check to see if **state_fact** exists via **print**. Use the **.exists()** method with engine as the argument.\n",
    "* Drop all the tables via the **metadata** using the **.drop_all()** method.\n",
    "* Use a print statement to check if the **census** table exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Connect to the database and create a new table (state_fact2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(census_sql_data)\n",
    "inspector = inspect(engine)\n",
    "table_names = inspector.get_table_names()\n",
    "print('Engine Table Names: \\n', table_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = engine.connect()\n",
    "metadata = MetaData()\n",
    "metadata.reflect(bind=engine)\n",
    "state_fact = metadata.tables['state_fact']\n",
    "\n",
    "results = connection.execute(select(state_fact)).fetchall()\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "_dtypes = {'id': String(256),\n",
    "           'name': String(256),\n",
    "           'abbreviation': String(256),\n",
    "           'country': String(256),\n",
    "           'type': String(256),\n",
    "           'sort': String(256),\n",
    "           'status': String(256),\n",
    "           'occupied': String(256),\n",
    "           'notes': String(256),\n",
    "           'fips_state': String(256),\n",
    "           'assoc_press': String(256),\n",
    "           'standard_federal_region': String(256),\n",
    "           'census_region': String(256),\n",
    "           'census_region_name': String(256),\n",
    "           'census_division': String(256),\n",
    "           'census_division_name': String(256),\n",
    "           'circuit_court': String(256)}\n",
    "\n",
    "df.columns = _dtypes.keys()\n",
    "\n",
    "df.to_sql('state_fact2', con=engine, index=False, if_exists='replace', dtype=_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Complete the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_fact2 = Table('state_fact2', metadata, autoload_with=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the state_fact table\n",
    "state_fact2.drop(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if state_fact exists\n",
    "# state_fact2.exists(engine)  # existings is no longer an attribute\n",
    "\n",
    "# Check if the table exists in the database\n",
    "table_name = 'state_fact2'\n",
    "if state_fact2 in inspector.get_table_names():\n",
    "    print(f\"The table '{table_name}' exists.\")\n",
    "else:\n",
    "    print(f\"The table '{table_name}' does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Make a backup copy of your census db\n",
    "* Recreate state_fact2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all tables\n",
    "metadata.drop_all(engine)\n",
    "\n",
    "# Check to see if census exists\n",
    "table_name = 'state_fact2'\n",
    "if state_fact2 in inspector.get_table_names():\n",
    "    print(f\"The table '{table_name}' exists.\")\n",
    "else:\n",
    "    print(f\"The table '{table_name}' does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "Here, you will bring together all of the skills you acquired in the previous chapters to work on a real life project! From connecting to a database, to populating it, to reading and querying it, you will have a chance to apply all the key concepts you learned in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Census Case Study\n",
    "\n",
    "* Preparing SQLAlchemy and the Database\n",
    "* Loading Data into the Database\n",
    "* Solving Data Science Problems with Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: Preparing SQLAlchemy and the Database\n",
    "\n",
    "* Create an Engine and MetaData object\n",
    "\n",
    "```python\n",
    "from sqlalchemy import create_engine, MetaData\n",
    "engine = create_engine('sqlite:///census_nyc.sqlite')\n",
    "metadata = MetaData()\n",
    "```\n",
    "\n",
    "* Create and save the census table\n",
    "\n",
    "```python\n",
    "from sqlalchemy import (Table, Column, String, Integer, Decimal, Boolean)\n",
    "employees = Table('employees', metadata,\n",
    "                  Column('id', Integer()),\n",
    "                  Column('name', String(255)),\n",
    "                  Column('salary', Decimal()),\n",
    "                  Column('active', Boolean()))\n",
    "metadata.create_all(engine)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study Explorations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup the Engine and the MetaData\n",
    "\n",
    "In this exercise, your job is to create an engine to the database that will be used in this chapter. Then, you need to initialize its metadata.\n",
    "\n",
    "Recall how you did this in Chapter 1 by leveraging create_engine() and MetaData.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Import create_engine and MetaData from sqlalchemy.\n",
    "* Create an engine to the chapter 5 database by using 'sqlite:///chapter5.sqlite' as the connection string.\n",
    "* Create a MetaData object as metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import create_engine, MetaData\n",
    "# from sqlalchemy import create_engine, MetaData -> done at top of notebook\n",
    "\n",
    "# Define an engine to connect to chapter5.sqlite: engine\n",
    "engine = create_engine('sqlite:///chapter5.sqlite')\n",
    "\n",
    "# Initialize MetaData: metadata\n",
    "metadata = MetaData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Table to the Database\n",
    "\n",
    "Having setup the engine and initialized the metadata, you will now define the census table object and then create it in the database using the metadata and engine from the previous exercise. To create it in the database, you will have to use the .create_all() method on the metadata with engine as the argument.\n",
    "\n",
    "It may help to refer back to the [Chapter 4 exercise](#creating-and-manipulating-your-own-databases) in which you learned how to create a table.\n",
    "\n",
    "Instructions\n",
    "\n",
    "* Import Table, Column, String, and Integer from sqlalchemy.\n",
    "* Define a census table with the following columns:\n",
    "    * 'state' - String - length of 30\n",
    "    * 'sex' - String - length of 1\n",
    "    * 'age' - Integer\n",
    "    * 'pop2000' - Integer\n",
    "    * 'pop2008' - Integer\n",
    "* Create the table in the database using the metadata and engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Table, Column, String, and Integer\n",
    "# from sqlalchemy import Table, Column, String, Integer -> done at top of notebook\n",
    "\n",
    "# Build a census table: census\n",
    "census = Table('census', metadata,\n",
    "               Column('state', String(30)),\n",
    "               Column('sex', String(1)),\n",
    "               Column('age', Integer()),\n",
    "               Column('pop2000', Integer()),\n",
    "               Column('pop2008', Integer()))\n",
    "\n",
    "# Create the table in the database\n",
    "metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populating the Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2: Populating the Database\n",
    "\n",
    "* Load a CSV file into a values list\n",
    "\n",
    "```python\n",
    "values_list = []\n",
    "for row in csv_reader:\n",
    "    data = {'state': row[0], 'sex': row[1],\n",
    "            'age': row[2], 'pop2000': row[3],\n",
    "            'pop2008': row[4]}\n",
    "    values_list.append(data)\n",
    "```\n",
    "\n",
    "* Insert the values list into the census table\n",
    "\n",
    "```python\n",
    "from sqlalchemy import insert\n",
    "stmt = insert(employees)\n",
    "result_proxy = connection.execute(stmt, values_list)\n",
    "print(result_proxy.rowcount)\n",
    "Out: 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study Explorations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the Data from the CSV\n",
    "\n",
    "Leverage the Python CSV module from the standard library and load the data into a list of dictionaries.\n",
    "\n",
    "It may help to refer back to the [Chapter 4 exercise](#creating-and-manipulating-your-own-databases) in which you did something similar.\n",
    "\n",
    "Instructions\n",
    "\n",
    "* Create an empty list called values_list.\n",
    "* Iterate over the rows of csv_reader with a for loop, creating a dictionary called data for each row and append it to values_list.\n",
    "    * Within the for loop, row will be a list whose entries are 'state' , 'sex', 'age', 'pop2000' and 'pop2008' (in that order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list: values_list\n",
    "values_list = list()\n",
    "\n",
    "with open(census_csv_data, newline='\\n') as csvfile:\n",
    "    csv_reader = csv.reader(csvfile)\n",
    "    \n",
    "    # Iterate over the rows\n",
    "    for row in csv_reader:\n",
    "        \n",
    "        # Create a dictionary with the values\n",
    "        data = {'state': row[0],\n",
    "                'sex': row[1],\n",
    "                'age':row[2],\n",
    "                'pop2000': row[3],\n",
    "                'pop2008': row[4]}\n",
    "        \n",
    "        # Append the dictionary to the values list\n",
    "        values_list.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data from a list into the Table\n",
    "\n",
    "Using the multiple insert pattern, in this exercise, you will load the data from values_list into the table.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Import insert from sqlalchemy.\n",
    "* Build an insert statement for the census table.\n",
    "* Execute the statement stmt along with values_list. You will need to pass them both as arguments to connection.execute().\n",
    "* Print the rowcount attribute of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import insert\n",
    "# from sqlalchemy import insert -> done at top of notebook\n",
    "\n",
    "# Build insert statement: stmt\n",
    "stmt = insert(census)\n",
    "\n",
    "# Use values_list to insert data: results\n",
    "connection = engine.connect()\n",
    "results = connection.execute(stmt, values_list)\n",
    "\n",
    "# Print rowcount\n",
    "results.rowcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3: Answering Data Science Questions with Queries\n",
    "\n",
    "* Determine Average Age for Males and Females\n",
    "\n",
    "```python\n",
    "from sqlalchemy import select\n",
    "stmt = select(census.columns.sex,\n",
    "              (func.sum(census.columns.pop2008 * census.columns.age) /\n",
    "               func.sum(census.columns.pop2008)).label('average_age'))\n",
    "stmt = stmt.group_by('census.columns.sex')\n",
    "results = connection.execute(stmt).fetchall()\n",
    "```\n",
    "\n",
    "* Determine the percentage of Females for each state\n",
    "\n",
    "```python\n",
    "from sqlalchemy import case, cast, Float\n",
    "stmt = select((func.sum(...: case((census.columns.state == 'New York',\n",
    "                                    census.columns.pop2008)...: , else_=0)) /\n",
    "               cast(func.sum(census.columns.pop2008), Float) * 100).label('ny_percent'))\n",
    "```\n",
    "\n",
    "* Determine the top 5 states by population change from 2000 to 2008\n",
    "\n",
    "```python\n",
    "stmt = select(census.columns.age,\n",
    "              (census.columns.pop2008 - census.columns.pop2000).label('pop_change'))\n",
    "stmt = stmt.order_by('pop_change')\n",
    "stmt = stmt.limit(5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study Explorations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a Query to Determine the Average Age by Population\n",
    "\n",
    "In this exercise, you will use the **func.sum()** and **group_by()** methods to first determine the average age weighted by the population in 2008, and then group by sex.\n",
    "\n",
    "As Jason discussed in the video, a weighted average is calculated as the sum of the product of the weights and averages divided by the sum of all the weights.\n",
    "\n",
    "For example, the following statement determines the average age weighted by the population in 2000:\n",
    "\n",
    "```sql\n",
    "stmt = select(census.columns.sex,\n",
    "    (func.sum(census.columns.pop2000 * census.columns.age) /\n",
    "    func.sum(census.columns.pop2000)).label('average_age')\n",
    "    )\n",
    "```\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Import select from sqlalchemy.\n",
    "* Build a statement to:\n",
    "    * Select sex from the census table.\n",
    "    * Select the average age weighted by the population in 2008 (pop2008). See the example given in the assignment text to see how you can do this. Label this average age calculation as 'average_age'.\n",
    "* Group the query by sex.\n",
    "* Execute the query and store it as results.\n",
    "* Loop over results and print the sex and average_age for each record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import select\n",
    "# from sqlalchemy import select -> done at top of notebook\n",
    "\n",
    "# Calculate weighted average age: stmt\n",
    "stmt = select(census.columns.sex,\n",
    "              (func.sum(census.columns.pop2008 * census.columns.age) /\n",
    "               func.sum(census.columns.pop2008)).label('average_age'))\n",
    "\n",
    "# Group by sex\n",
    "stmt = stmt.group_by('sex')\n",
    "\n",
    "# Execute the query and store the results: results\n",
    "results = connection.execute(stmt).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the average age by sex\n",
    "for result in results:\n",
    "    print(result[0], result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a Query to Determine the Percentage of Population by Gender and State\n",
    "\n",
    "In this exercise, you will write a query to determine the percentage of the population in 2000 that comprised of women. You will group this query by state.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Import case, cast and Float from sqlalchemy.\n",
    "* Define a statement to select state and the percentage of females in 2000.\n",
    "    * Inside func.sum(), use case() to select females (using the sex column) from pop2000. Remember to specify else_=0 if the sex is not 'F'.\n",
    "    * To get the percentage, divide the number of females in the year 2000 by the overall population in 2000. Cast the divisor - census.columns.pop2000 - to Float before multiplying by 100.\n",
    "* Group the query by state.\n",
    "* Execute the query and store it as results.\n",
    "* Print state and percent_female for each record. This has been done for you, so hit 'Submit Answer' to see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import case, cast and Float from sqlalchemy\n",
    "# from sqlalchemy import case, cast, Float -> done at top of notebook\n",
    "\n",
    "# Build a query to calculate the percentage of females in 2000: stmt\n",
    "stmt = select(census.columns.state, (func.sum(case((census.columns.sex == 'F', census.columns.pop2000), else_=0)) /\n",
    "                                     cast(func.sum(census.columns.pop2000), Float) * 100).label('percent_female'))\n",
    "\n",
    "# Group By state\n",
    "stmt = stmt.group_by('state')\n",
    "\n",
    "# Execute the query and store the results: results\n",
    "results = connection.execute(stmt).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the percentage\n",
    "for result in results:\n",
    "    print(f'State: {result.state}, Percent Female: {result.percent_female}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results, columns=['State', 'Percent_Female'])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a Query to Determine the Difference by State from the 2000 and 2008 Censuses\n",
    "\n",
    "In this final exercise, you will write a query to calculate the states that changed the most in population. You will limit your query to display only the top 10 states.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Build a statement to:\n",
    "    * Select **state**.\n",
    "    * Calculate the difference in population between 2008 (**pop2008**) and 2000 (**pop2000**).\n",
    "* Group the query by **census.columns.state** using the **.group_by()** method on **stmt**.\n",
    "* Order by **'pop_change'** in descending order using the **.order_by()** method with the **desc()** function on **'pop_change'**.\n",
    "* Limit the query to the top **10** states using the **.limit()** method.\n",
    "* Execute the query and store it as **results**.\n",
    "* Print the state and the population change for each result. This has been done for you, so hit 'Submit Answer' to see the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build query to return state name and population difference from 2008 to 2000\n",
    "stmt = select(census.columns.state,\n",
    "              (census.columns.pop2008 - census.columns.pop2000).label('pop_change'))\n",
    "\n",
    "# Group by State\n",
    "stmt = stmt.group_by(census.columns.state)\n",
    "\n",
    "# Order by Population Change\n",
    "stmt = stmt.order_by(desc('pop_change'))\n",
    "\n",
    "# Limit to top 10\n",
    "stmt = stmt.limit(10)\n",
    "\n",
    "# Use connection to execute the statement and fetch all results\n",
    "results = connection.execute(stmt).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the state and population change for each record\n",
    "for result in results:\n",
    "    print(f'{result.state}:{result.pop_change}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_change_df = pd.DataFrame(results, columns=['State', 'Population_Change'])\n",
    "pop_change_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Certificate\n",
    "\n",
    "![](https://raw.githubusercontent.com/trenton3983/DataCamp/master/Images/intro_to_databases_in_python/2019-03-23_intro_to_databases_in_python_certficate.JPG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
